{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45677aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cloud_storage.redshift_connection import redshift_connection\n",
    "\n",
    "connection = redshift_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f137d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# Sample Feature Definitions\n",
    "# -------------------------\n",
    "\n",
    "# Batch size = 2\n",
    "# 1. One-hot feature: genre (5 categories)\n",
    "x_genre = torch.tensor([\n",
    "    [0, 1, 0, 0, 0],  # genre = category 1\n",
    "    [0, 0, 0, 1, 0],  # genre = category 3\n",
    "], dtype=torch.float32)  # shape: [2, 5]\n",
    "\n",
    "# 2. Learnable embedding: item_id (embedding dim = 8)\n",
    "item_ids = torch.tensor([12, 45])  # example item indices\n",
    "item_embedding_layer = nn.Embedding(num_embeddings=100, embedding_dim=8)\n",
    "x_item_id = item_embedding_layer(item_ids)  # shape: [2, 8]\n",
    "\n",
    "# 3. Pretrained embedding: text features (dim = 16)\n",
    "x_text_embed = torch.tensor([\n",
    "    [0.1] * 16,\n",
    "    [0.2] * 16\n",
    "], dtype=torch.float32)  # shape: [2, 16]\n",
    "\n",
    "# -------------------------\n",
    "# Combine all features\n",
    "# -------------------------\n",
    "x_all = torch.cat([x_genre, x_item_id, x_text_embed], dim=1)  # shape: [2, 5+8+16 = 29]\n",
    "\n",
    "# -------------------------\n",
    "# Item Tower (MLP)\n",
    "# -------------------------\n",
    "# item_tower = nn.Sequential(\n",
    "#     nn.Linear(x_all.shape[1], 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 32),  # final item embedding\n",
    "# )\n",
    "\n",
    "# item_vector = item_tower(x_all)  # shape: [2, 32]\n",
    "\n",
    "# print(\"Final item embedding vector (per item):\")\n",
    "# print(item_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f7a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000, -1.1790, -0.1624, -0.1445,\n",
       "          0.3887,  0.3142, -0.5061,  1.8720, -0.5338,  0.1000,  0.1000,  0.1000,\n",
       "          0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
       "          0.1000,  0.1000,  0.1000,  0.1000,  0.1000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.2250, -0.1304, -1.1441,\n",
       "          1.3484,  0.3573, -0.5984,  1.9021, -0.2330,  0.2000,  0.2000,  0.2000,\n",
       "          0.2000,  0.2000,  0.2000,  0.2000,  0.2000,  0.2000,  0.2000,  0.2000,\n",
       "          0.2000,  0.2000,  0.2000,  0.2000,  0.2000]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5f3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleTower(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(64, output_dim)  # Output layer (no activation)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79488b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Define the shared tower class\n",
    "class SimpleTower(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define full model combining both towers\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, user_dim, item_dim, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_tower = SimpleTower(user_dim, embed_dim)\n",
    "        self.item_tower = SimpleTower(item_dim, embed_dim)\n",
    "\n",
    "    def forward(self, user_x, item_x):\n",
    "        user_vec = self.user_tower(user_x)\n",
    "        item_vec = self.item_tower(item_x)\n",
    "        # Combine via dot product\n",
    "        score = (user_vec * item_vec).sum(dim=1, keepdim=True)  # shape: [batch_size, 1]\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54a4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "user_input = torch.randn(4, 64)  # batch_size x user_input_dim\n",
    "item_input = torch.randn(4, 48)  # batch_size x item_input_dim\n",
    "\n",
    "# Create and run model\n",
    "model = TwoTowerModel(user_dim=64, item_dim=48)\n",
    "output = model(user_input, item_input)\n",
    "\n",
    "# # Visualize with torchviz\n",
    "# dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "# dot.format = 'png'\n",
    "# dot.render(\"two_tower_graph\")  # creates two_tower_graph.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668f4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "# Assuming TwoTowerModel and towers are already defined\n",
    "\n",
    "# Create model\n",
    "model = TwoTowerModel(user_dim=64, item_dim=48)\n",
    "\n",
    "# Dummy inputs (use batch size >1 to avoid BatchNorm errors)\n",
    "user_input = torch.randn(2, 64)\n",
    "item_input = torch.randn(2, 48)\n",
    "\n",
    "# Create a TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"runs/two_tower_example\")\n",
    "\n",
    "# Log the model graph\n",
    "writer.add_graph(model, (user_input, item_input))\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8f21a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "W0805 18:46:34.738121 6145716224 plugin_event_accumulator.py:369] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0805 18:46:34.739761 6145716224 plugin_event_accumulator.py:369] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.20.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b345b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleTower(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleTower(input_dim=64)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de76dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d281e979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleTower                              [1, 32]                   --\n",
       "├─Sequential: 1-1                        [1, 32]                   --\n",
       "│    └─Linear: 2-1                       [1, 128]                  8,320\n",
       "│    └─BatchNorm1d: 2-2                  [1, 128]                  256\n",
       "│    └─ReLU: 2-3                         [1, 128]                  --\n",
       "│    └─Dropout: 2-4                      [1, 128]                  --\n",
       "│    └─Linear: 2-5                       [1, 64]                   8,256\n",
       "│    └─BatchNorm1d: 2-6                  [1, 64]                   128\n",
       "│    └─ReLU: 2-7                         [1, 64]                   --\n",
       "│    └─Dropout: 2-8                      [1, 64]                   --\n",
       "│    └─Linear: 2-9                       [1, 32]                   2,080\n",
       "==========================================================================================\n",
       "Total params: 19,040\n",
       "Trainable params: 19,040\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.08\n",
       "Estimated Total Size (MB): 0.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = SimpleTower(input_dim=64)\n",
    "summary(model, input_size=(1, 64))  # batch_size x input_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdedc9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TwoTowerModel.forward() missing 1 required positional argument: 'item_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m dummy_input = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m64\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# model = SimpleTower(input_dim=64)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m writer.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:841\u001b[39m, in \u001b[36mSummaryWriter.add_graph\u001b[39m\u001b[34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[39m\n\u001b[32m    838\u001b[39m torch._C._log_api_usage_once(\u001b[33m\"\u001b[39m\u001b[33mtensorboard.logging.add_graph\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    839\u001b[39m \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[32m    840\u001b[39m \u001b[38;5;28mself\u001b[39m._get_file_writer().add_graph(\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:326\u001b[39m, in \u001b[36mgraph\u001b[39m\u001b[34m(model, args, verbose, use_strict_trace)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         trace = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m         graph = trace.graph\n\u001b[32m    328\u001b[39m         torch._C._jit_pass_inline(graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/jit/_trace.py:1002\u001b[39m, in \u001b[36mtrace\u001b[39m\u001b[34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[39m\n\u001b[32m    989\u001b[39m     warnings.warn(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`optimize` is deprecated and has no effect. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    992\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    993\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    994\u001b[39m     )\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    997\u001b[39m     check_if_torch_exportable,\n\u001b[32m    998\u001b[39m     log_torch_jit_trace_exportability,\n\u001b[32m    999\u001b[39m     log_torchscript_usage,\n\u001b[32m   1000\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m traced_func = \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m log_torchscript_usage(\u001b[33m\"\u001b[39m\u001b[33mtrace\u001b[39m\u001b[33m\"\u001b[39m, model_id=_get_model_id(traced_func))\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_if_torch_exportable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/jit/_trace.py:696\u001b[39m, in \u001b[36m_trace_impl\u001b[39m\u001b[34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[39m\n\u001b[32m    694\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    695\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mexample_kwarg_inputs should be a dict\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    710\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    711\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func.\u001b[34m__self__\u001b[39m, torch.nn.Module)\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    713\u001b[39m ):\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/jit/_trace.py:1279\u001b[39m, in \u001b[36mtrace_module\u001b[39m\u001b[34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[39m\n\u001b[32m   1277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1278\u001b[39m     example_inputs = make_tuple(example_inputs)\n\u001b[32m-> \u001b[39m\u001b[32m1279\u001b[39m     \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_c\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1290\u001b[39m check_trace_method = module._c._get_method(method_name)\n\u001b[32m   1292\u001b[39m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1741\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1739\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1741\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1743\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[31mTypeError\u001b[39m: TwoTowerModel.forward() missing 1 required positional argument: 'item_x'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "dummy_input = torch.randn(1, 64)\n",
    "model = SimpleTower(input_dim=64)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61bd4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.20.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/IPython/utils/_process_posix.py:130\u001b[39m, in \u001b[36mProcessHandler.system\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     res_idx = \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mprint\u001b[39m(child.before[out_size:].decode(enc, \u001b[33m'\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m'\u001b[39m), end=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/spawnbase.py:383\u001b[39m, in \u001b[36mSpawnBase.expect_list\u001b[39m\u001b[34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/expect.py:169\u001b[39m, in \u001b[36mExpecter.expect_loop\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m incoming = \u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.spawn.delayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/pty_spawn.py:500\u001b[39m, in \u001b[36mspawn.read_nonblocking\u001b[39m\u001b[34m(self, size, timeout)\u001b[39m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (timeout != \u001b[32m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m).read_nonblocking(size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/pty_spawn.py:450\u001b[39m, in \u001b[36mspawn.read_nonblocking.<locals>.select\u001b[39m\u001b[34m(timeout)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/utils.py:143\u001b[39m, in \u001b[36mselect_ignore_interrupts\u001b[39m\u001b[34m(iwtd, owtd, ewtd, timeout)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtensorboard --logdir=runs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/ipykernel/zmqshell.py:657\u001b[39m, in \u001b[36mZMQInteractiveShell.system_piped\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    655\u001b[39m         \u001b[38;5;28mself\u001b[39m.user_ns[\u001b[33m\"\u001b[39m\u001b[33m_exit_code\u001b[39m\u001b[33m\"\u001b[39m] = system(cmd)\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m     \u001b[38;5;28mself\u001b[39m.user_ns[\u001b[33m\"\u001b[39m\u001b[33m_exit_code\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/IPython/utils/_process_posix.py:141\u001b[39m, in \u001b[36mProcessHandler.system\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    136\u001b[39m         out_size = \u001b[38;5;28mlen\u001b[39m(child.before)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/pty_spawn.py:578\u001b[39m, in \u001b[36mspawn.sendline\u001b[39m\u001b[34m(self, s)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Wraps send(), sending string ``s`` to child process, with\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[33;03m``os.linesep`` automatically appended. Returns number of bytes\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[33;03mwritten.  Only a limited number of bytes may be sent for each\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[33;03mline in the default terminal mode, see docstring of :meth:`send`.\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    577\u001b[39m s = \u001b[38;5;28mself\u001b[39m._coerce_send_string(s)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinesep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pexpect/pty_spawn.py:569\u001b[39m, in \u001b[36mspawn.send\u001b[39m\u001b[34m(self, s)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;28mself\u001b[39m._log(s, \u001b[33m'\u001b[39m\u001b[33msend\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    568\u001b[39m b = \u001b[38;5;28mself\u001b[39m._encoder.encode(s, final=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], output_dim=32, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Generic tower for user or item.\n",
    "\n",
    "        Args:\n",
    "        - input_dim (int): Input feature dimension\n",
    "        - hidden_dims (list of int): Hidden layer dimensions\n",
    "        - output_dim (int): Final output size\n",
    "        - dropout (float): Dropout rate between layers\n",
    "        \"\"\"\n",
    "        super(Tower, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "\n",
    "        # Hidden layers\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(current_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            current_dim = h_dim\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(current_dim, output_dim))\n",
    "\n",
    "        self.tower = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tower(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4ff674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cloud_storage.redshift_connection import redshift_connection\n",
    "\n",
    "connection = redshift_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6fde86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 12:12:38,691 - side - DEBUG - Attempting to read SQL file: sql_files/item_query.sql\n",
      "2025-08-06 12:12:38,696 - side - INFO - Successfully read SQL file: sql_files/item_query.sql\n",
      "2025-08-06 12:12:41,283 - read_shift - INFO - Connected to Redshift successfully.\n",
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/cloud_storage/redshift_connection.py:82: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "2025-08-06 12:13:54,029 - read_shift - INFO - Query executed successfully, retrieved 12191 rows.\n",
      "2025-08-06 12:13:54,032 - read_shift - INFO - Connection closed.\n"
     ]
    }
   ],
   "source": [
    "item_query = 'sql_files/item_query.sql'\n",
    "book_df = connection.redshift_query_fetching_as_df(item_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8fb979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>book_series</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>rights</th>\n",
       "      <th>illustrators</th>\n",
       "      <th>interactive</th>\n",
       "      <th>search_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>clicks_students</th>\n",
       "      <th>quality_clicks</th>\n",
       "      <th>quality_clicks_students</th>\n",
       "      <th>students_completed_book</th>\n",
       "      <th>students_completed_75_per_book</th>\n",
       "      <th>per_75_completed_unique_books</th>\n",
       "      <th>completion_rate</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>total_pages</th>\n",
       "      <th>read_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>9781638973744</td>\n",
       "      <td>Forces and Changes in Motion</td>\n",
       "      <td>Christina,Earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Forces, Friction, Magnet, Motion, Physical Sci...</td>\n",
       "      <td>...</td>\n",
       "      <td>505.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>78.43</td>\n",
       "      <td>277827.0</td>\n",
       "      <td>13524.0</td>\n",
       "      <td>9573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>9781427121141</td>\n",
       "      <td>Forensic Investigations of the Ancient Egyptians</td>\n",
       "      <td>James,Bow</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Ancient Civilizations, Forensic Science, Egypt...</td>\n",
       "      <td>...</td>\n",
       "      <td>208.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>62.37</td>\n",
       "      <td>46343.0</td>\n",
       "      <td>10757.0</td>\n",
       "      <td>7613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>453</td>\n",
       "      <td>9780778789222</td>\n",
       "      <td>Soccer in Action</td>\n",
       "      <td>Niki,Walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>1999-10-31</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>44.16</td>\n",
       "      <td>66151.0</td>\n",
       "      <td>11222.0</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4717</td>\n",
       "      <td>9781039625440</td>\n",
       "      <td>Scared (Pè) Bilingual Eng/Cre</td>\n",
       "      <td>Amy,Culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Scared, emotion, yell, thunderstorm, cry, hug</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>43.80</td>\n",
       "      <td>6869.0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>1348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4808</td>\n",
       "      <td>9781532420764</td>\n",
       "      <td>Cody Eats / Cody Come</td>\n",
       "      <td>Brenda Ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>World</td>\n",
       "      <td>Brenda Ponnay</td>\n",
       "      <td>None</td>\n",
       "      <td>cody the dog, dog book, dog reader, dog beginn...</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.54</td>\n",
       "      <td>112017.0</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>2627.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      book_isbn                                        book_title  \\\n",
       "0   210  9781638973744                      Forces and Changes in Motion   \n",
       "1   212  9781427121141  Forensic Investigations of the Ancient Egyptians   \n",
       "2   453  9780778789222                                  Soccer in Action   \n",
       "3  4717  9781039625440                     Scared (Pè) Bilingual Eng/Cre   \n",
       "4  4808  9781532420764                             Cody Eats / Cody Come   \n",
       "\n",
       "            authors                            book_series publication_date  \\\n",
       "0  Christina,Earley                       Physical Science       2022-02-01   \n",
       "1         James,Bow  Forensic Footprints of Ancient Worlds       2018-09-25   \n",
       "2       Niki,Walker                       Sports in Action       1999-10-31   \n",
       "3     Amy,Culliford                                   None       2022-08-15   \n",
       "4     Brenda Ponnay                 Cody the Dog Bilingual       2020-09-17   \n",
       "\n",
       "  rights   illustrators interactive  \\\n",
       "0  World           None       False   \n",
       "1  World           None       False   \n",
       "2  World           None       False   \n",
       "3  World           None       False   \n",
       "4  World  Brenda Ponnay        None   \n",
       "\n",
       "                                     search_keywords  ... clicks_students  \\\n",
       "0  Forces, Friction, Magnet, Motion, Physical Sci...  ...           505.0   \n",
       "1  Ancient Civilizations, Forensic Science, Egypt...  ...           208.0   \n",
       "2                                               None  ...           273.0   \n",
       "3      Scared, emotion, yell, thunderstorm, cry, hug  ...           165.0   \n",
       "4  cody the dog, dog book, dog reader, dog beginn...  ...           601.0   \n",
       "\n",
       "  quality_clicks quality_clicks_students students_completed_book  \\\n",
       "0          543.0                   453.0                   360.0   \n",
       "1          247.0                   189.0                   121.0   \n",
       "2          285.0                   223.0                   102.0   \n",
       "3          140.0                   131.0                    60.0   \n",
       "4          703.0                   536.0                   272.0   \n",
       "\n",
       "  students_completed_75_per_book per_75_completed_unique_books  \\\n",
       "0                          439.0                          95.0   \n",
       "1                          187.0                          96.0   \n",
       "2                          208.0                          90.0   \n",
       "3                          117.0                          85.0   \n",
       "4                          446.0                          81.0   \n",
       "\n",
       "  completion_rate time_spent  total_pages read_pages  \n",
       "0           78.43   277827.0      13524.0     9573.0  \n",
       "1           62.37    46343.0      10757.0     7613.0  \n",
       "2           44.16    66151.0      11222.0     5775.0  \n",
       "3           43.80     6869.0       2561.0     1348.0  \n",
       "4           49.54   112017.0       4650.0     2627.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "998fc76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/cktdjg3x6vvdzgvlht84ndk00000gp/T/ipykernel_46063/3279698797.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  book_df['long_description'].fillna('unk',inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'book_isbn', 'book_title', 'authors', 'book_series',\n",
       "       'publication_date', 'rights', 'illustrators', 'interactive',\n",
       "       'search_keywords', 'top_hundred', 'book_type', 'long_description',\n",
       "       'bestseller', 'editor_recommended', 'animated', 'top_twenty',\n",
       "       'top_fifty', 'page_count', 'min_grade', 'max_grade',\n",
       "       'readable_page_count', 'min_reading_age', 'max_reading_age',\n",
       "       'read_along_audio', 'read_along_with_highlighting', 'orientation',\n",
       "       'last_reading_page_number', 'book_format', 'language_book',\n",
       "       'publisher_name', 'fiction_nonfiction', 'reading_skill_name',\n",
       "       'theme_name', 'category_name', 'book_code', 'grade_name', 'book_code',\n",
       "       'clicks', 'clicks_students', 'quality_clicks',\n",
       "       'quality_clicks_students', 'students_completed_book',\n",
       "       'students_completed_75_per_book', 'per_75_completed_unique_books',\n",
       "       'completion_rate', 'time_spent', 'total_pages', 'read_pages',\n",
       "       'title_plus_author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df['title_plus_author'] = book_df.apply(lambda x:x['book_title'].lower()+' by '+x['authors'].lower(),axis=1)\n",
    "book_df['long_description'].fillna('unk',inplace=True)\n",
    "book_df['long_description'] = book_df.apply(lambda x:x['long_description'].lower(),axis=1)\n",
    "book_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5d1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12191, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d6682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>fiction_nonfiction</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>language_book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>Science &amp; Nature</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>People &amp; Places, Science &amp; Nature</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>Growing Up</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>Growing Up</td>\n",
       "      <td>Haitian French Creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>Funny Stories, Animals</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count fiction_nonfiction  \\\n",
       "0                   21        Non-Fiction   \n",
       "1                   31        Non-Fiction   \n",
       "2                   31        Non-Fiction   \n",
       "3                   13        Non-Fiction   \n",
       "4                    5            Fiction   \n",
       "\n",
       "                                  reading_skill_name  \\\n",
       "0  Making Inferences, Illustrations or other Visu...   \n",
       "1  Illustrations or other Visual Elements, Fact a...   \n",
       "2  Making Inferences, Illustrations or other Visu...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                theme_name                      category_name  \\\n",
       "0                  Fun Science, Technology                   Science & Nature   \n",
       "1  History, Technology, Places of Interest  People & Places, Science & Nature   \n",
       "2  Sports & Games, Fitness, Healthy Habits                         Growing Up   \n",
       "3    Emotions & Feelings, Family & Friends                         Growing Up   \n",
       "4     Funny Stories, Our Friends in Nature             Funny Stories, Animals   \n",
       "\n",
       "           language_book  \n",
       "0                English  \n",
       "1                English  \n",
       "2                English  \n",
       "3  Haitian French Creole  \n",
       "4                Spanish  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['book_isbn', 'title_plus_author', 'book_series', 'book_type', 'long_description','min_grade', 'max_grade',\n",
    "       'readable_page_count','fiction_nonfiction', 'reading_skill_name','theme_name', 'category_name','language_book']\n",
    "\n",
    "book_df_final = book_df[columns]\n",
    "book_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f6f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tta/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def encode_column_with_sentence_transformer(df: pd.DataFrame, column: str, model_name: str = 'all-MiniLM-L6-v2') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encodes a column of text into embeddings using a sentence-transformer model.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        column (str): Column name to encode.\n",
    "        model_name (str): Pretrained sentence-transformers model name.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (num_rows, embedding_dim)\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Fill missing values\n",
    "    texts = df[column].fillna(\"unk\").astype(str).tolist()\n",
    "    \n",
    "    # Encode with model\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    \n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/381 [00:00<?, ?it/s]/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|██████████| 381/381 [00:10<00:00, 34.70it/s]\n"
     ]
    }
   ],
   "source": [
    "emb = encode_column_with_sentence_transformer(book_df_final,'title_plus_author')\n",
    "# Convert embeddings to DataFrame\n",
    "emb_df = pd.DataFrame(emb, columns=[f\"emb_title_author_{i}\" for i in range(emb.shape[1])])\n",
    "\n",
    "# Combine with book_id\n",
    "book_embedding_df = pd.concat([book_df_final[[\"book_isbn\"]], emb_df], axis=1)\n",
    "\n",
    "# Save to file\n",
    "# book_embedding_df.to_parquet(\"book_embeddings.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_desc = encode_column_with_sentence_transformer(book_df_final,'long_description')\n",
    "# Convert embeddings to DataFrame\n",
    "emb_desc_df = pd.DataFrame(emb_desc, columns=[f\"emb_desc_{i}\" for i in range(emb.shape[1])])\n",
    "\n",
    "# Combine with book_id\n",
    "long_description_df = pd.concat([book_df_final[[\"book_isbn\"]], emb_desc_df], axis=1)\n",
    "\n",
    "# Save to file\n",
    "# book_embedding_df.to_parquet(\"book_embeddings.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a61a22fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>emb_desc_0</th>\n",
       "      <th>emb_desc_1</th>\n",
       "      <th>emb_desc_2</th>\n",
       "      <th>emb_desc_3</th>\n",
       "      <th>emb_desc_4</th>\n",
       "      <th>emb_desc_5</th>\n",
       "      <th>emb_desc_6</th>\n",
       "      <th>emb_desc_7</th>\n",
       "      <th>emb_desc_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_desc_374</th>\n",
       "      <th>emb_desc_375</th>\n",
       "      <th>emb_desc_376</th>\n",
       "      <th>emb_desc_377</th>\n",
       "      <th>emb_desc_378</th>\n",
       "      <th>emb_desc_379</th>\n",
       "      <th>emb_desc_380</th>\n",
       "      <th>emb_desc_381</th>\n",
       "      <th>emb_desc_382</th>\n",
       "      <th>emb_desc_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>-0.008896</td>\n",
       "      <td>0.058679</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.038774</td>\n",
       "      <td>-0.046619</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.094449</td>\n",
       "      <td>-0.024867</td>\n",
       "      <td>0.067868</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>0.044612</td>\n",
       "      <td>-0.092573</td>\n",
       "      <td>-0.056998</td>\n",
       "      <td>-0.019073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>-0.093507</td>\n",
       "      <td>0.124757</td>\n",
       "      <td>-0.006754</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.071832</td>\n",
       "      <td>-0.049502</td>\n",
       "      <td>-0.028421</td>\n",
       "      <td>-0.055279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043926</td>\n",
       "      <td>-0.049684</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.091449</td>\n",
       "      <td>0.039405</td>\n",
       "      <td>-0.071128</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.049927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>-0.051905</td>\n",
       "      <td>-0.016251</td>\n",
       "      <td>0.053230</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.100513</td>\n",
       "      <td>-0.054278</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>0.070474</td>\n",
       "      <td>-0.075082</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>0.088831</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.084495</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.083350</td>\n",
       "      <td>0.057772</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.082917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070714</td>\n",
       "      <td>-0.009329</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.071399</td>\n",
       "      <td>-0.027583</td>\n",
       "      <td>0.094227</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.040795</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>0.019917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>-0.056846</td>\n",
       "      <td>-0.069584</td>\n",
       "      <td>0.079330</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>-0.105333</td>\n",
       "      <td>-0.035210</td>\n",
       "      <td>0.068424</td>\n",
       "      <td>-0.054729</td>\n",
       "      <td>-0.026249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079174</td>\n",
       "      <td>-0.019516</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>-0.031867</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.065822</td>\n",
       "      <td>0.110249</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>-0.061654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn  emb_desc_0  emb_desc_1  emb_desc_2  emb_desc_3  emb_desc_4  \\\n",
       "0  9781638973744    0.013931   -0.008896    0.058679    0.112187    0.024721   \n",
       "1  9781427121141   -0.093507    0.124757   -0.006754   -0.001654   -0.014084   \n",
       "2  9780778789222    0.002869    0.049008    0.008290   -0.051905   -0.016251   \n",
       "3  9781039625440    0.088831    0.010486    0.014458    0.084495    0.012768   \n",
       "4  9781532420764   -0.056846   -0.069584    0.079330    0.018258   -0.105333   \n",
       "\n",
       "   emb_desc_5  emb_desc_6  emb_desc_7  emb_desc_8  ...  emb_desc_374  \\\n",
       "0    0.006103    0.038774   -0.046619    0.032334  ...      0.068244   \n",
       "1   -0.071832   -0.049502   -0.028421   -0.055279  ...      0.043926   \n",
       "2    0.053230    0.039608    0.007936    0.059096  ...      0.015007   \n",
       "3    0.083350    0.057772    0.015923    0.082917  ...      0.070714   \n",
       "4   -0.035210    0.068424   -0.054729   -0.026249  ...      0.079174   \n",
       "\n",
       "   emb_desc_375  emb_desc_376  emb_desc_377  emb_desc_378  emb_desc_379  \\\n",
       "0      0.094449     -0.024867      0.067868     -0.036735     -0.007186   \n",
       "1     -0.049684      0.007033      0.091449      0.039405     -0.071128   \n",
       "2      0.100513     -0.054278      0.026744      0.008615      0.064617   \n",
       "3     -0.009329      0.015837      0.071399     -0.027583      0.094227   \n",
       "4     -0.019516      0.004677     -0.031867      0.024795      0.065822   \n",
       "\n",
       "   emb_desc_380  emb_desc_381  emb_desc_382  emb_desc_383  \n",
       "0      0.044612     -0.092573     -0.056998     -0.019073  \n",
       "1      0.183100      0.005550      0.047619     -0.049927  \n",
       "2      0.070474     -0.075082     -0.000960      0.117753  \n",
       "3      0.018915      0.040795     -0.014076      0.019917  \n",
       "4      0.110249      0.105666      0.005809     -0.061654  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_description_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>fiction_nonfiction</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>language_book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>Science &amp; Nature</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>People &amp; Places, Science &amp; Nature</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>Growing Up</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Non-Fiction</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>Growing Up</td>\n",
       "      <td>Haitian French Creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>Funny Stories, Animals</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count fiction_nonfiction  \\\n",
       "0                 0.42        Non-Fiction   \n",
       "1                 0.62        Non-Fiction   \n",
       "2                 0.62        Non-Fiction   \n",
       "3                 0.26        Non-Fiction   \n",
       "4                 0.10            Fiction   \n",
       "\n",
       "                                  reading_skill_name  \\\n",
       "0  Making Inferences, Illustrations or other Visu...   \n",
       "1  Illustrations or other Visual Elements, Fact a...   \n",
       "2  Making Inferences, Illustrations or other Visu...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                theme_name                      category_name  \\\n",
       "0                  Fun Science, Technology                   Science & Nature   \n",
       "1  History, Technology, Places of Interest  People & Places, Science & Nature   \n",
       "2  Sports & Games, Fitness, Healthy Habits                         Growing Up   \n",
       "3    Emotions & Feelings, Family & Friends                         Growing Up   \n",
       "4     Funny Stories, Our Friends in Nature             Funny Stories, Animals   \n",
       "\n",
       "           language_book  \n",
       "0                English  \n",
       "1                English  \n",
       "2                English  \n",
       "3  Haitian French Creole  \n",
       "4                Spanish  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df_final['readable_page_count'] = book_df_final['readable_page_count']/50\n",
    "book_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3db716f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fiction_nonfiction'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'fiction_nonfiction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbook_df_final_v1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfiction_nonfiction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tta/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'fiction_nonfiction'"
     ]
    }
   ],
   "source": [
    "book_df_final_v1['fiction_nonfiction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8d9af00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/cktdjg3x6vvdzgvlht84ndk00000gp/T/ipykernel_46063/498868689.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  book_df_final['book_type_binary'] = np.where(book_df.book_type == 'PDF',1,0)\n",
      "/var/folders/yx/cktdjg3x6vvdzgvlht84ndk00000gp/T/ipykernel_46063/498868689.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  book_df_final['fiction_nonfiction'].fillna('unk',inplace =True)\n",
      "/var/folders/yx/cktdjg3x6vvdzgvlht84ndk00000gp/T/ipykernel_46063/498868689.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  book_df_final['fiction_nonfiction'].fillna('unk',inplace =True)\n"
     ]
    }
   ],
   "source": [
    "book_df_final['book_type_binary'] = np.where(book_df.book_type == 'PDF',1,0)\n",
    "book_df_final['fiction_nonfiction'].fillna('unk',inplace =True)\n",
    "book_df_final_v1 = pd.get_dummies(book_df_final, columns=['fiction_nonfiction'], prefix='fn')\n",
    "book_df_final_v1 = pd.get_dummies(book_df_final_v1, columns=['language_book'], prefix='lang')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c1710e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_isbn', 'title_plus_author', 'book_series', 'book_type',\n",
       "       'long_description', 'min_grade', 'max_grade', 'readable_page_count',\n",
       "       'reading_skill_name', 'theme_name', 'category_name', 'book_type_binary',\n",
       "       'fiction_nonfiction_binary', 'fn_Fiction', 'fn_Non-Fiction', 'fn_unk',\n",
       "       'lang_English', 'lang_French', 'lang_Haitian French Creole',\n",
       "       'lang_Mandarin', 'lang_Portuguese', 'lang_Spanish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df_final_v1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "['book_isbn', 'book_series','min_grade', 'max_grade', 'reading_skill_name','theme_name', 'category_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def encode_column_with_vocab(series: pd.Series, col_name: str, existing_vocab=None):\n",
    "    \"\"\"\n",
    "    Encodes a single categorical column for embedding.\n",
    "    Returns encoded indices, vocab, inverse map.\n",
    "    \"\"\"\n",
    "    series = series.fillna('unk').astype(str)\n",
    "\n",
    "    if existing_vocab is None:\n",
    "        unique_vals = sorted(series.unique().tolist())\n",
    "        if 'unk' not in unique_vals:\n",
    "            unique_vals.append('unk')\n",
    "        vocab_map = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    else:\n",
    "        vocab_map = existing_vocab\n",
    "\n",
    "    inverse_map = {idx: val for val, idx in vocab_map.items()}\n",
    "    encoded_series = series.map(lambda x: vocab_map.get(x, vocab_map['unk']))\n",
    "    encoded_series.name = f\"{col_name}_idx\"\n",
    "    return encoded_series, vocab_map, inverse_map\n",
    "\n",
    "\n",
    "def create_embedding_layer(vocab_size, embedding_dim):\n",
    "    \"\"\"\n",
    "    Creates a PyTorch embedding layer with given vocab size and dimension.\n",
    "    \"\"\"\n",
    "    return nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "\n",
    "def get_embeddings_for_column(encoded_series, embedding_layer):\n",
    "    \"\"\"\n",
    "    Returns embedding vectors for each value in the encoded column.\n",
    "    \"\"\"\n",
    "    input_tensor = torch.tensor(encoded_series.tolist(), dtype=torch.long)\n",
    "    return embedding_layer(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30671db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_list = ['pk', 'k', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "grade_to_idx = {g: i for i, g in enumerate(grade_list)}\n",
    "\n",
    "class ConvertRangeEmb():\n",
    "    def __init__(self,data_list,emb_dim =4):\n",
    "        self.grade_list = data_list\n",
    "        self.num_grades = len(self.grade_list)\n",
    "        self.grade_to_idx = {g: i for i, g in enumerate(grade_list)}\n",
    "        self.grade_embedding = nn.Embedding(self.num_grades, emb_dim)\n",
    "\n",
    "    def _get_range(self,min_g, max_g):\n",
    "        start_idx = self.grade_to_idx[min_g]\n",
    "        end_idx = self.grade_to_idx[max_g]\n",
    "        return grade_list[start_idx:end_idx + 1]\n",
    "\n",
    "    def convertor(self,min_g, max_g,):\n",
    "        book_grades = self._get_range(min_g, max_g)\n",
    "        num_grades = self.grade_list\n",
    "        grade_indices = grade_indices = torch.tensor(\n",
    "    [self.grade_to_idx[g] for g in book_grades],\n",
    "    dtype=torch.long  # 🔧 this fixes the error\n",
    ")\n",
    "\n",
    "        embedded = self.grade_embedding(grade_indices)\n",
    "        return embedded.mean(dim=0)  \n",
    "\n",
    "# Get embeddings\n",
    "  # shape: [3, 8]\n",
    "# book_embedding =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf22e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = convert_range_emb(grade_list,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5efcd5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1958, -0.8391, -0.4423, -0.9212], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas._get_range('pk','2')\n",
    "clas.convertor('pk','2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b598af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df_final_v1.min_grade.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "be5800a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c7a7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize converter\n",
    "grade_converter = ConvertRangeEmb(data_list=grade_list, emb_dim=4)\n",
    "\n",
    "\n",
    "# Apply to each row\n",
    "book_df_final_v1[\"grade_emb\"] = book_df_final_v1.apply(\n",
    "    lambda row: grade_converter.convertor(row[\"min_grade\"], row[\"max_grade\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert embedding column to separate columns\n",
    "emb_df = pd.DataFrame(book_df_final_v1[\"grade_emb\"].tolist(), columns=[f\"grade_emb_{i}\" for i in range(4)])\n",
    "\n",
    "# Combine with original\n",
    "df_final = pd.concat([book_df_final_v1.drop(\"grade_emb\", axis=1), emb_df], axis=1)\n",
    "\n",
    "# Save as Parquet\n",
    "# df_final.to_parquet(\"book_with_grade_embeddings.parquet\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9de8dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_English</th>\n",
       "      <th>lang_French</th>\n",
       "      <th>lang_Haitian French Creole</th>\n",
       "      <th>lang_Mandarin</th>\n",
       "      <th>lang_Portuguese</th>\n",
       "      <th>lang_Spanish</th>\n",
       "      <th>grade_emb_0</th>\n",
       "      <th>grade_emb_1</th>\n",
       "      <th>grade_emb_2</th>\n",
       "      <th>grade_emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(-0.3938, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0132, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(-0.3938, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0132, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count                                 reading_skill_name  \\\n",
       "0                 0.42  Making Inferences, Illustrations or other Visu...   \n",
       "1                 0.62  Illustrations or other Visual Elements, Fact a...   \n",
       "2                 0.62  Making Inferences, Illustrations or other Visu...   \n",
       "3                 0.26                                               None   \n",
       "4                 0.10                                               None   \n",
       "\n",
       "                                theme_name  ... lang_English  lang_French  \\\n",
       "0                  Fun Science, Technology  ...         True        False   \n",
       "1  History, Technology, Places of Interest  ...         True        False   \n",
       "2  Sports & Games, Fitness, Healthy Habits  ...         True        False   \n",
       "3    Emotions & Feelings, Family & Friends  ...        False        False   \n",
       "4     Funny Stories, Our Friends in Nature  ...        False        False   \n",
       "\n",
       "   lang_Haitian French Creole  lang_Mandarin  lang_Portuguese  lang_Spanish  \\\n",
       "0                       False          False            False         False   \n",
       "1                       False          False            False         False   \n",
       "2                       False          False            False         False   \n",
       "3                        True          False            False         False   \n",
       "4                       False          False            False          True   \n",
       "\n",
       "                                  grade_emb_0  \\\n",
       "0   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3938, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3938, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_1  \\\n",
       "0  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.0132, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.0132, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_2  \\\n",
       "0   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_3  \n",
       "0  tensor(-1.2436, grad_fn=<UnbindBackward0>)  \n",
       "1  tensor(-1.2436, grad_fn=<UnbindBackward0>)  \n",
       "2  tensor(-1.2436, grad_fn=<UnbindBackward0>)  \n",
       "3   tensor(0.4681, grad_fn=<UnbindBackward0>)  \n",
       "4   tensor(0.4681, grad_fn=<UnbindBackward0>)  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc59b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "['book_isbn', 'book_series', 'reading_skill_name','theme_name', 'category_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5f921a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThemeEmbedder(nn.Module):\n",
    "    def __init__(self, df, col, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        df['themes'] = df[col].fillna('unk').apply(lambda x: [t.strip().lower() for t in x.split(',') if t.strip()])\n",
    "\n",
    "        all_themes = sorted(set(chain.from_iterable(df['themes'])))\n",
    "        self.theme_to_idx = {theme: idx for idx, theme in enumerate(all_themes)}\n",
    "        if 'unk' not in self.theme_to_idx:\n",
    "            self.theme_to_idx['unk'] = len(self.theme_to_idx)\n",
    "\n",
    "        df['theme_ids'] = df['themes'].apply(lambda theme_list: [self.theme_to_idx[t] for t in theme_list if t in self.theme_to_idx])\n",
    "\n",
    "        self.embedding = nn.Embedding(len(self.theme_to_idx), embedding_dim)\n",
    "        self.theme_ids_batch = df['theme_ids'].tolist()\n",
    "\n",
    "        self.df = df  # Keep a reference if needed\n",
    "\n",
    "    def forward(self):\n",
    "        embeddings = []\n",
    "        for theme_ids in self.theme_ids_batch:\n",
    "            if not theme_ids:\n",
    "                embeddings.append(torch.zeros(self.embedding.embedding_dim, requires_grad=True))  # Keep graph\n",
    "            else:\n",
    "                ids_tensor = torch.tensor(theme_ids, dtype=torch.long)\n",
    "                emb = self.embedding(ids_tensor)\n",
    "                pooled = emb.mean(dim=0)  # This tensor still has grad_fn\n",
    "                embeddings.append(pooled)\n",
    "        return embeddings  # List of tensors (not stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ffc2350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12827f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = ThemeEmbedder(pd.DataFrame(df_final['theme_name']),'theme_name',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5150, -1.0864, -0.3459, -0.8359,  0.4598,  0.1705,  0.5889,  0.7324],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2772,  0.1951, -0.0494,  0.7112,  0.4024,  0.9126, -1.2159,  0.0738],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0516, -0.1987, -1.0108,  1.1954,  0.9227,  0.0437, -0.3688,  0.2706],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4919,  0.6516, -0.9011,  0.1746, -0.7292,  0.5869,  0.3551, -0.5469],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0578,  0.6440, -0.1595,  0.8692,  0.1641,  0.8108,  0.1317,  0.2230],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2980,  1.0166, -0.1654, -0.3365,  0.1544,  0.8970,  0.7464, -0.4284],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4783,  0.0297, -0.1364, -0.4721, -0.0165,  0.8626,  0.4596,  0.1763],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3180, -0.4839,  0.5259,  0.0888, -0.2746,  0.9000,  0.0847,  0.2303],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1702,  0.3225,  0.8702,  0.3770, -0.0888,  0.6157,  0.9770,  0.1115],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2375,  0.5001, -0.3278,  0.1162, -0.1044,  0.9958,  1.7784, -0.9082],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0420,  0.6973, -0.3498,  1.3619, -0.2004,  0.1089, -0.1390,  0.1247],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5529, -0.0034, -0.2246, -1.3148,  0.1730,  1.3198,  1.6179,  0.0572],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7081,  0.6645, -0.6743,  0.4235, -0.8032, -0.5496,  1.4963, -2.0017],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4610,  0.6101, -0.0379,  0.4261, -0.4304, -0.5187,  0.4019, -0.3962],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0965, -0.5362, -0.5133, -0.2833, -0.0244, -0.3916, -0.2199, -0.7172],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.8221, -0.2650,  1.0105,  1.1647, -0.9558,  1.1278,  0.4897,  1.3593],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9103, -0.3535, -0.6275,  0.0758,  0.9791,  0.0259,  0.4511, -0.0813],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4943,  0.6825, -0.6006,  0.9549, -0.4873,  0.4717,  0.8923, -0.1048],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7619,  0.2752, -0.9214,  0.0451,  0.2405, -0.1944,  0.3906, -0.3350],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4411,  1.0936, -0.4012, -0.3335, -0.9077,  0.5655,  1.1828, -1.0958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9419,  0.2946, -0.6286, -0.0874, -1.1122, -0.1976,  0.3860, -0.6776],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1666,  0.8657,  0.4534,  0.1337,  0.9178,  0.1636,  0.1682, -0.7696],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-3.5068e-04, -3.5577e-01, -4.3289e-02,  7.9474e-01,  1.0655e+00,\n",
       "          6.9698e-01, -3.3529e-02, -8.8864e-01], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5620, -0.7368, -0.5872,  0.0992, -0.2712,  1.6400, -0.2671, -0.6587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4959,  1.0143, -0.2637,  0.4121, -0.5544,  0.6741,  0.7938, -0.2663],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4248, -0.2675, -0.0400,  0.1660, -0.2595, -0.4632,  0.0136, -0.4993],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2720, -0.8677, -1.0678,  0.1206,  0.0449,  0.8131, -0.6555, -0.0284],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7991,  0.9565, -1.0042, -0.3530,  0.1640,  0.0343, -0.2555,  0.0979],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3833, -0.0625, -0.5016, -0.5527, -0.2629,  0.6200,  0.3017,  0.1698],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8015,  0.9922,  0.4302,  0.2805,  0.0788,  0.1021, -0.0048, -0.7250],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1184, -0.1889, -0.0825,  0.7021,  0.6249, -0.6749,  0.0184,  0.4810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3464,  0.4791, -0.3365,  0.1416,  0.7265,  0.8576,  0.5639,  0.1467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0886,  0.1709, -0.0917,  0.0454, -0.9622, -0.1481,  1.0262, -0.7568],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2873,  2.8371, -1.4442, -1.7260,  1.0404, -0.9951,  1.9913, -0.5889],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7514,  0.7476, -1.0872,  0.0292,  0.9619, -0.5375, -0.7743,  0.6024],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5995, -0.9263,  0.0058,  0.1726,  0.1106, -0.4426, -0.2015, -0.4745],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7991,  0.9565, -1.0042, -0.3530,  0.1640,  0.0343, -0.2555,  0.0979],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9681, -0.9865,  0.3714, -0.0160, -0.1233, -0.5084,  0.2100,  0.2667],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0524,  0.8183, -0.1813,  0.4703, -0.1317, -0.0988,  0.8816, -0.3666],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1058, -0.2264,  0.0350,  0.0945, -0.0318,  1.1189, -0.0497,  0.0121],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9242,  0.5735, -0.8820,  0.7119,  0.6763, -0.0179, -0.4221,  0.1359],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1444,  0.2177, -0.8451, -0.9736,  0.7165, -0.9484,  0.3197,  0.2896],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6108, -2.0319,  0.0576, -0.4974,  0.5455,  0.5958, -0.0240,  0.0534],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2853,  0.5818, -0.8896, -0.8834, -0.3285,  0.1384, -0.1550, -0.7396],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0718,  0.4821,  0.2822,  1.0349, -0.6745,  0.7706,  1.4954, -0.5340],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5506, -0.1608, -1.2983,  1.3832,  0.5144,  0.9503,  0.1563,  0.2671],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3625,  0.3368, -1.2373,  1.0466,  0.9524, -0.0130,  0.0325,  0.0432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5698, -0.2130,  0.6188,  0.3520, -0.1138,  1.0709,  0.0875,  1.7304],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3650,  0.6867,  0.1314,  0.0993, -0.9046,  0.6464,  0.9931, -1.0672],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3803, -0.9789,  0.2188, -0.4742,  0.0332,  0.1896,  0.2697, -1.2665],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0941, -0.3285,  0.3477,  0.0500, -1.0275,  1.4532, -0.1651, -2.4763],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2896,  0.4682, -0.4143, -0.6717, -0.0246,  0.5780,  1.8352, -2.0477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7081,  0.6645, -0.6743,  0.4235, -0.8032, -0.5496,  1.4963, -2.0017],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3403, -0.6657, -0.0482,  0.4301,  0.1179,  0.3042,  1.2318, -0.8565],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0512,  0.3859,  0.1402,  0.8062,  1.0378, -0.4110, -0.2322,  1.0157],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0660, -0.7044, -0.4425,  0.0610, -0.8088,  1.6181, -0.6597, -1.4024],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0686, -0.0073,  0.7047, -0.1226,  0.0790, -0.3185, -1.9402,  0.3766],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3853,  0.2094, -0.3159, -0.4351,  1.5092,  0.4876,  0.9173,  0.1747],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2375,  0.5001, -0.3278,  0.1162, -0.1044,  0.9958,  1.7784, -0.9082],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0347,  0.2428, -1.4150, -0.4618,  1.1582, -0.9553,  0.1864,  0.4159],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7859, -0.4222, -0.5408,  0.8310, -0.3538,  1.1398, -0.2284,  0.6650],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1375, -1.5031, -0.2345, -0.9498,  0.4620,  0.9965, -0.0106, -0.6075],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6076, -0.3255,  0.3080,  0.9181,  0.3917,  0.8406,  0.1409, -0.1393],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0518, -0.0642, -0.4543,  0.5370,  0.8524, -1.5981, -0.4521, -0.5370],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 5.1618e-05, -9.2661e-01, -4.3573e-02, -8.1513e-01,  7.2447e-02,\n",
       "          1.5581e+00,  6.6882e-01, -1.3828e+00], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4931, -0.4237,  0.6830, -0.5270,  0.4068, -0.0466,  0.6762,  0.5227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.1557, -0.1547,  1.8397, -1.3330,  0.1982,  2.1752, -0.9636, -0.9388],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3544, -0.9626,  0.9538,  0.3063,  0.0649, -0.1503, -0.5547,  1.5080],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4074, -0.5744, -0.0026, -1.5637, -0.0780,  0.0571,  0.5171, -0.9459],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2737, -0.6579, -0.5788,  0.6993, -0.2087, -0.9587, -0.9145, -0.2417],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2544, -0.7801, -0.0326, -0.4089, -0.6544,  0.4949, -0.3974, -0.8130],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2951,  0.1601, -1.0466,  1.4997,  1.1596,  0.2834, -0.5456,  0.5746],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3137, -0.7152, -0.1236, -0.6345,  0.1884, -0.0475,  0.2554, -0.8724],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3706, -0.3424, -0.1833, -0.9579, -0.0152,  0.2029,  0.8025,  0.1876],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7108,  0.2128,  0.2783, -0.0328, -0.1083,  0.6896, -0.3723,  0.2599],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2549,  1.3792,  0.1371,  0.2329,  1.7248, -0.6655,  0.4562, -0.2789],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1886, -0.8428, -0.8355,  0.3621,  0.3577,  0.6131,  0.0552, -0.1261],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3108, -0.1147, -0.7595,  1.0285,  0.0802, -0.2905, -0.4469,  0.0078],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8599,  0.2354, -0.3578, -0.0137, -0.3834,  0.7703, -0.6729, -0.8917],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3307,  0.7457, -0.5271, -0.3625,  0.3865, -0.2851,  0.5837, -0.3290],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6762, -0.0966, -0.6425, -1.1534, -0.4345, -0.3850,  0.8305, -1.6222],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1648,  0.5320,  0.5980, -0.2844, -0.5677,  1.2050,  0.4710,  0.6978],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5096,  0.6275, -0.7153, -0.0772, -1.0346,  0.3036,  1.5334, -1.4229],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8490, -1.9178,  0.2531,  0.2100,  0.5579,  0.0297,  0.6171,  0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5489,  0.5379, -0.3404,  0.5889, -1.0600,  0.1846,  1.0943, -0.4105],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5825, -0.0716,  1.3243,  0.2369,  1.1701,  1.1523, -0.9678,  0.1227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2544, -0.7801, -0.0326, -0.4089, -0.6544,  0.4949, -0.3974, -0.8130],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8469, -0.4289,  0.2474, -0.2420, -0.5734,  0.0396,  0.2738, -0.4354],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5323, -0.0811, -0.0820, -0.0821,  0.4819,  0.9085,  0.2726,  0.0663],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.0906, -1.4129,  0.6801,  0.5599, -0.1634,  0.6614,  0.2262,  1.0368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2772,  0.1951, -0.0494,  0.7112,  0.4024,  0.9126, -1.2159,  0.0738],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7081,  0.6645, -0.6743,  0.4235, -0.8032, -0.5496,  1.4963, -2.0017],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0414, -1.3669,  0.5056,  0.5282,  0.0533,  0.3957,  0.5746,  0.7395],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1164, -0.8852,  0.1694, -0.7867,  0.5945,  0.6899,  0.6900, -0.4798],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1157,  0.3713, -0.6652,  0.5071,  0.4212,  1.3121,  0.7720,  0.5589],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0420,  0.6973, -0.3498,  1.3619, -0.2004,  0.1089, -0.1390,  0.1247],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4747,  0.3603, -1.4617,  0.0285, -0.6501,  0.5266, -0.2564, -0.0544],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3060,  0.2418, -1.1001, -1.4619, -0.1809, -0.4191,  0.7680,  0.1061],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1683,  0.5749, -0.2100,  0.8423,  0.4169,  0.8492,  0.0110, -0.3740],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9103, -0.3535, -0.6275,  0.0758,  0.9791,  0.0259,  0.4511, -0.0813],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3064,  0.1378,  2.1686, -1.1119,  0.3434, -0.2551,  0.0605, -1.1142],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2945, -0.5727, -0.5743, -0.0430,  0.3167,  0.5712,  0.5203,  0.1368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2074, -1.5977,  0.5862,  0.1727,  0.6616,  0.3906, -0.2509,  0.6459],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9134,  0.1365, -0.5795,  0.5028,  1.3867, -0.2154,  0.3820,  0.1158],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2548,  0.3619, -0.6159, -0.9033, -0.3719,  1.0008,  0.9217, -0.0242],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-6.7536e-02, -3.2272e-01,  1.2348e-01, -1.5879e+00,  1.2760e-03,\n",
       "          6.2279e-01,  1.3849e+00, -1.4608e-02], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1913, -0.2242, -0.0886, -0.2805,  0.2356,  0.0833,  0.7776, -0.4166],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2549,  1.3792,  0.1371,  0.2329,  1.7248, -0.6655,  0.4562, -0.2789],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9235, -1.0276, -0.0807, -0.9887,  0.3858,  0.8386,  0.7292, -0.1143],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6124, -0.7993, -0.2230,  0.3631,  0.7361, -0.1088,  0.5622, -0.0329],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2283,  0.0338, -0.1605,  0.7175,  0.7513,  0.3408, -0.6783, -0.3288],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2359,  0.7860, -1.1697,  0.9634,  0.2602,  0.3777,  0.8401,  0.4616],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5936, -0.2323, -1.9010,  1.1909, -0.3721,  0.6297, -1.3004,  0.5507],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1375, -1.5031, -0.2345, -0.9498,  0.4620,  0.9965, -0.0106, -0.6075],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2775,  0.9367,  0.3012,  0.8137,  0.2182,  0.4871, -0.1059, -0.4227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3052,  0.5840, -0.5937, -0.3889,  0.3521,  0.3609, -0.2752,  0.7658],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6378, -0.8759,  0.6337,  0.3510,  0.1612,  0.8184,  0.4635,  0.5294],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2699, -0.5027, -0.5251, -0.4124, -0.5041, -0.2980,  0.4140, -0.5071],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3250, -0.1818,  0.4707, -0.3463, -0.3490, -0.8730, -0.1383, -0.6619],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9103, -0.3535, -0.6275,  0.0758,  0.9791,  0.0259,  0.4511, -0.0813],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2036,  0.2442, -0.7671, -1.6811, -0.4280, -0.2721,  0.3065,  0.5537],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0290,  0.1363,  0.6470,  0.0154, -0.0321,  1.4919,  0.8680,  0.8229],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4606,  0.3365, -0.6478, -0.5384,  0.3593, -1.1466,  0.5654, -0.3278],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5429, -0.0620,  0.6441,  0.4654,  0.4306, -0.4068, -0.5752, -0.0670],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6359,  0.2194,  0.2061,  0.0474, -0.7514,  0.0932,  0.6091, -0.5248],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8597,  0.2773,  0.0553,  0.9847, -0.3420, -0.2570, -0.5570, -1.3652],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8599,  0.2354, -0.3578, -0.0137, -0.3834,  0.7703, -0.6729, -0.8917],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0777, -0.1802, -1.0212,  0.7552, -0.4748,  0.0440, -0.7163, -0.4890],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6834, -0.4984,  0.0703, -0.0433,  0.7952, -1.3590,  0.0090, -0.6749],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 5.1618e-05, -9.2661e-01, -4.3573e-02, -8.1513e-01,  7.2447e-02,\n",
       "          1.5581e+00,  6.6882e-01, -1.3828e+00], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0525,  0.6690,  0.2273,  0.2732, -0.5044,  0.1494,  0.5423, -1.2429],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8902, -0.1892, -0.4258, -0.0630,  0.5981, -0.0874,  0.4544,  0.2167],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1421,  0.8350, -0.4513, -0.7806, -0.9901, -0.0423,  1.3400, -1.0779],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6455,  1.3437,  0.9044, -0.1982, -0.4344,  0.7392,  0.1783, -0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7525, -0.4870,  0.9434,  0.1369, -0.4472, -0.1555, -0.4350,  1.1888],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1935, -0.0893, -0.5744, -0.7054,  0.6980, -1.0620,  0.6620,  0.4789],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0153,  0.5839, -0.6581,  0.3285, -0.1006,  0.3831,  0.5810, -0.1445],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3803, -0.9789,  0.2188, -0.4742,  0.0332,  0.1896,  0.2697, -1.2665],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5936, -0.2323, -1.9010,  1.1909, -0.3721,  0.6297, -1.3004,  0.5507],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2980,  1.0166, -0.1654, -0.3365,  0.1544,  0.8970,  0.7464, -0.4284],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0860,  0.0579, -0.3718,  0.4040,  0.0790,  0.2088,  0.1766,  0.1416],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2794, -0.6658,  0.1888, -0.1526, -0.1031,  1.2342,  0.5116,  0.4543],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2945, -0.5727, -0.5743, -0.0430,  0.3167,  0.5712,  0.5203,  0.1368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3084, -1.4268, -0.0164, -1.1467,  0.4865,  0.4688,  0.5660, -0.4769],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0129,  0.3473, -0.0234,  0.5988, -0.2474,  0.2403,  0.4408,  0.6295],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2670,  0.7301, -0.0625, -1.2186, -0.3275,  0.9628,  0.6376, -0.2958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4074, -0.5744, -0.0026, -1.5637, -0.0780,  0.0571,  0.5171, -0.9459],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.7270, -1.2305, -0.2764, -0.0516, -0.2921, -0.6588,  0.2272, -0.4309],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0443,  0.6020,  0.6740,  0.0154,  0.5752,  1.1287, -0.5299,  0.0219],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1794, -1.5753, -0.1606, -0.5397,  0.6700, -0.6693,  0.4436, -0.5099],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1222, -0.4371,  0.2138, -0.1137,  0.7320, -1.0298,  0.1943, -0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4931, -0.4237,  0.6830, -0.5270,  0.4068, -0.0466,  0.6762,  0.5227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0402,  0.1816, -0.1746,  0.3232,  0.1386,  0.4416,  0.8663,  0.6501],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0251, -0.1532,  0.0327, -1.8261,  0.5695,  0.7059,  0.9044, -0.9408],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6193,  0.5463, -0.0657, -0.3467,  0.8045,  0.8291,  0.6865,  0.8572],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1472,  0.1441,  0.0194,  0.2865, -0.0573,  0.3311,  0.0427,  0.0741],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2055, -0.1731, -0.1553,  0.5871, -0.3962,  0.4169, -0.3203, -0.0861],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7738, -0.3338, -0.1260,  0.5516,  0.1372,  0.0097,  0.3027,  0.3467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2544, -0.7801, -0.0326, -0.4089, -0.6544,  0.4949, -0.3974, -0.8130],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3063,  0.1008, -0.2727, -0.1631,  0.7639, -0.9621,  0.6189,  0.2825],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3060,  0.2418, -1.1001, -1.4619, -0.1809, -0.4191,  0.7680,  0.1061],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1058, -0.2264,  0.0350,  0.0945, -0.0318,  1.1189, -0.0497,  0.0121],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5509,  0.3074,  0.3618,  0.4470,  0.1485, -0.0068, -0.2737, -0.7040],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  1.0443, -0.0893,  0.9263, -0.6861,  0.1096,  0.7754, -0.1534],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0609, -0.1504,  0.0132, -0.0435,  0.5072,  0.0736,  1.1531, -0.3639],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3351,  0.6524, -1.0291,  0.3834,  0.1495,  0.5809,  1.1887,  0.3079],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4527,  1.1374, -0.4823,  0.6753,  0.0897,  0.7980, -0.9043,  0.7917],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6779, -0.2392,  0.3601,  0.4512, -0.3398,  1.1218,  0.1301,  0.4612],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0256,  0.8630,  0.2887,  0.3503, -0.7687, -0.1390, -1.5316,  0.4096],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7243, -0.5485,  0.5957, -0.5980,  0.3749, -0.9390,  0.0554, -0.6237],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7903, -0.5894,  0.5318,  0.3235,  0.4785,  0.2710,  0.1227, -0.3022],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.7562, -1.0701,  1.2127, -0.2055, -0.3704, -1.5640, -0.0468, -0.0817],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1222, -0.4371,  0.2138, -0.1137,  0.7320, -1.0298,  0.1943, -0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4133, -0.1541, -0.5812,  0.5374, -0.5261, -0.2488, -0.4243, -1.0088],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.7642, -0.6409,  0.8334,  0.2247,  0.1160,  1.0308,  0.5037,  0.8574],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2678, -0.5007, -1.3165,  0.6641, -0.0529,  1.1458, -0.5874,  0.3179],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4353, -0.9164, -0.9391,  0.5868,  0.4491, -0.4359, -0.0151, -0.3373],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2564, -1.3949,  0.0701, -0.3588,  0.4067,  0.8866,  0.5092,  0.6627],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2359,  0.7860, -1.1697,  0.9634,  0.2602,  0.3777,  0.8401,  0.4616],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7903, -0.5894,  0.5318,  0.3235,  0.4785,  0.2710,  0.1227, -0.3022],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0370, -0.2293, -0.8372,  0.5527,  0.5455, -0.2578,  0.1843, -0.1377],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2544, -0.7801, -0.0326, -0.4089, -0.6544,  0.4949, -0.3974, -0.8130],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-3.5068e-04, -3.5577e-01, -4.3289e-02,  7.9474e-01,  1.0655e+00,\n",
       "          6.9698e-01, -3.3529e-02, -8.8864e-01], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5571, -0.8559,  0.3774, -0.8789, -0.5000, -0.6284, -0.1351, -0.2235],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1058, -0.2264,  0.0350,  0.0945, -0.0318,  1.1189, -0.0497,  0.0121],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1886, -0.8428, -0.8355,  0.3621,  0.3577,  0.6131,  0.0552, -0.1261],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6242, -0.0647, -0.5560, -0.3655, -0.5144,  0.0328,  0.7737, -0.4826],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3060,  0.2418, -1.1001, -1.4619, -0.1809, -0.4191,  0.7680,  0.1061],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0660, -0.7044, -0.4425,  0.0610, -0.8088,  1.6181, -0.6597, -1.4024],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3978,  0.8289,  0.0878,  0.1201, -0.1270,  0.4400,  0.3116,  0.0532],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3201,  0.7943, -0.0894, -0.1011,  1.6170, -0.0890,  0.6867, -0.0521],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3064,  0.1378,  2.1686, -1.1119,  0.3434, -0.2551,  0.0605, -1.1142],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0578,  0.6440, -0.1595,  0.8692,  0.1641,  0.8108,  0.1317,  0.2230],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0012, -0.7019,  0.0454,  0.2638,  0.4803,  1.1241, -0.1694,  0.3313],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4579, -0.8535, -1.2985, -0.5439,  0.5516,  0.7854, -0.2654,  0.2575],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5538, -0.4380,  0.7341,  0.6658,  1.4344,  0.0827, -0.7487,  0.8709],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4641, -0.2902, -0.2340,  0.1283,  0.4403,  0.1441,  0.0617,  0.3053],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1183, -0.0451, -0.4966, -0.2189, -0.1366,  0.2808,  1.1144, -0.5037],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9503,  0.0251, -0.6562, -0.3555,  0.7640,  1.6211,  1.0423,  0.1536],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1345,  1.7292, -0.0209,  0.7598, -0.7557,  0.2186,  1.0443, -0.1744],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5233, -0.7617,  1.2590,  1.2162,  1.3971, -0.1197, -1.5817,  1.2190],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4828, -0.1059, -0.4318, -0.7171,  0.2599,  0.5118,  0.5312,  0.8497],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.7056,  0.3941,  0.8665,  0.2108, -1.5410, -0.9368,  1.2490, -0.0177],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1554,  0.1488, -1.1348,  0.2098,  0.2100,  0.8060,  0.1191, -0.2036],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0660, -0.7044, -0.4425,  0.0610, -0.8088,  1.6181, -0.6597, -1.4024],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5579,  0.3454, -0.5770, -0.4672, -0.4208, -0.1189,  1.3874, -1.8905],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.3592, -2.5607,  0.3497, -0.0449,  0.6289,  0.1950, -0.0373,  0.7144],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7126,  0.4088,  0.8765,  0.4713,  0.7897,  1.0540, -1.1737, -0.1646],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5934,  0.3049, -0.1512,  0.2391, -0.4639,  0.4611,  0.6246,  0.4268],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1809, -1.5547, -0.7938,  0.7183,  0.7099, -0.3315,  0.8450,  0.4844],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2945, -0.5727, -0.5743, -0.0430,  0.3167,  0.5712,  0.5203,  0.1368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0941, -0.3285,  0.3477,  0.0500, -1.0275,  1.4532, -0.1651, -2.4763],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3853,  0.2094, -0.3159, -0.4351,  1.5092,  0.4876,  0.9173,  0.1747],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5651, -1.6323,  0.2863,  0.1771,  0.2856,  0.2425,  0.2763, -0.2161],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.3592, -2.5607,  0.3497, -0.0449,  0.6289,  0.1950, -0.0373,  0.7144],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3137, -0.7152, -0.1236, -0.6345,  0.1884, -0.0475,  0.2554, -0.8724],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.5385,  0.5571,  0.5738,  0.6988,  0.3845,  0.2311,  0.4730,  0.5402],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3098,  0.1479, -0.4650, -1.1712, -0.0665,  0.0728,  0.5201, -0.6443],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6124, -0.7993, -0.2230,  0.3631,  0.7361, -0.1088,  0.5622, -0.0329],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0579,  0.1730, -0.3503,  0.6253,  0.1982,  1.0946,  0.1296,  0.1770],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.0906, -1.4129,  0.6801,  0.5599, -0.1634,  0.6614,  0.2262,  1.0368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6821,  0.2081, -0.0504, -0.0033, -0.7715, -0.4684,  0.1333, -0.8185],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8215, -0.0418, -0.3492, -1.3418,  0.9266,  0.6151,  1.0433, -0.7467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1409, -1.0835,  0.7435,  0.2078, -0.0453, -2.5472, -0.5286, -1.0340],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2331,  1.2460, -0.7103,  0.4080,  0.0818,  0.3889, -0.6004,  0.0031],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1647,  0.1685, -0.1492,  1.0386,  0.6761,  0.8161,  0.0120,  0.5421],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2945, -0.5727, -0.5743, -0.0430,  0.3167,  0.5712,  0.5203,  0.1368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0931,  0.7602, -0.5286, -0.1944, -0.0664, -0.9514,  0.5077,  0.8472],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4256, -0.2626, -1.1418, -0.5288, -0.0140,  0.6861, -0.0655, -0.5587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8706,  0.5811, -0.6691, -0.7845,  0.2905,  0.4556,  0.8525, -0.2424],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7910,  0.1239, -0.7829,  0.6630, -0.6136, -0.4937, -0.0307, -0.2291],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7225, -0.2660, -1.2892,  0.5941, -1.0773,  0.3518,  0.0055, -0.3156],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7334,  0.6411, -0.3934,  0.5560,  0.1026, -0.0757,  0.5013,  0.4512],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8274,  0.2629,  0.2430, -0.1918,  0.5896,  0.5317,  0.3461,  0.0569],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1459, -0.0255, -1.0954,  0.7762,  0.7617, -0.3848, -0.1938,  0.5294],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4606,  0.3365, -0.6478, -0.5384,  0.3593, -1.1466,  0.5654, -0.3278],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1154, -0.4897,  0.3423,  0.4859, -0.1756,  0.8344, -0.2393, -0.9169],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2737, -0.6579, -0.5788,  0.6993, -0.2087, -0.9587, -0.9145, -0.2417],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2362,  0.1511,  0.0631, -0.1881, -0.1242,  0.1173,  0.2616, -0.2012],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.7056,  0.3941,  0.8665,  0.2108, -1.5410, -0.9368,  1.2490, -0.0177],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5525,  0.0917, -0.0727, -0.3889,  0.9951, -0.4470,  0.2467,  0.3901],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4554,  1.1215, -0.8226, -1.0531,  0.0754,  0.6702,  0.8155,  0.9174],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3423, -0.8841,  0.3880,  0.1075, -0.2469,  1.0622,  0.2396,  0.3759],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4080,  0.8064, -0.8747,  0.4157, -1.9550,  0.1356,  0.7407, -0.6134],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2078, -0.2487, -0.4453,  1.1778, -0.6640,  0.8787, -0.4053,  0.9550],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2831, -0.3123,  0.7256, -0.0946,  0.0920,  0.3259, -0.1173,  1.1370],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2413,  0.4945,  0.2142,  0.0808, -1.4432, -0.9606,  0.9639, -0.5649],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3559,  0.9529, -1.0224, -1.1339, -0.9281,  0.4235,  0.7876, -0.6594],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5150, -1.0864, -0.3459, -0.8359,  0.4598,  0.1705,  0.5889,  0.7324],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2372, -0.9180, -0.3118, -0.7839, -0.0800, -0.1917,  0.5412, -0.8433],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4261, -0.6668, -0.3750,  0.4686, -0.2887,  0.9180, -0.2738,  0.4342],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1587,  0.0121,  0.5871, -1.4466,  0.9522,  0.7774,  0.5118, -0.9904],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3068,  0.3300, -0.7024, -1.6912, -0.2920,  0.5830,  0.9785, -1.1638],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2134, -0.2471, -0.1866, -0.9365,  0.2717,  0.3031,  0.9082, -0.8338],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9242,  0.5735, -0.8820,  0.7119,  0.6763, -0.0179, -0.4221,  0.1359],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0154, -0.4618,  0.1087,  0.6029,  0.4105,  1.4100, -0.0379],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0387, -0.7493, -0.3451,  0.4823,  0.2283,  0.0575,  0.8162, -0.6834],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5936, -0.2323, -1.9010,  1.1909, -0.3721,  0.6297, -1.3004,  0.5507],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1432, -0.0590, -0.3753, -0.4802,  0.1674,  0.3867,  0.5075, -0.4617],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4145,  0.8610,  0.9164, -0.2274,  1.7211,  0.1274,  0.0914, -0.6842],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-3.5068e-04, -3.5577e-01, -4.3289e-02,  7.9474e-01,  1.0655e+00,\n",
       "          6.9698e-01, -3.3529e-02, -8.8864e-01], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7126,  0.4088,  0.8765,  0.4713,  0.7897,  1.0540, -1.1737, -0.1646],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8490, -1.9178,  0.2531,  0.2100,  0.5579,  0.0297,  0.6171,  0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8469, -0.4289,  0.2474, -0.2420, -0.5734,  0.0396,  0.2738, -0.4354],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3231, -0.4755, -0.8249,  0.6549, -0.0607, -0.2026, -0.1340, -0.2698],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6359,  0.2194,  0.2061,  0.0474, -0.7514,  0.0932,  0.6091, -0.5248],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6076, -0.3255,  0.3080,  0.9181,  0.3917,  0.8406,  0.1409, -0.1393],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3784,  0.1565, -0.6926,  0.7460,  0.0279, -0.0112,  1.2429, -1.3823],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3464,  0.4791, -0.3365,  0.1416,  0.7265,  0.8576,  0.5639,  0.1467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8811,  0.2950,  0.8046,  0.0716, -0.3706, -0.1475,  0.6957,  0.1294],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3650,  0.6867,  0.1314,  0.0993, -0.9046,  0.6464,  0.9931, -1.0672],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1744, -1.3982, -0.8551,  0.0649,  0.4164,  0.9257, -0.0931, -0.2900],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2034, -0.4932,  0.0616, -1.0489,  0.1587,  0.7716,  0.3113, -0.7788],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4712,  0.1057,  0.0362, -0.6961,  0.0442,  0.0721,  0.9430, -0.6650],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2011, -0.8899, -0.3716, -0.3204,  0.2232, -0.3166,  0.1550, -0.8916],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.2198,  0.4079, -1.2334, -1.1619,  1.0696, -0.3194,  1.2574,  1.2354],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5047,  0.1583,  0.2637,  0.5664,  0.8622, -0.1677,  0.9340, -1.0294],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2851,  0.0207, -0.7187,  0.8428,  0.4561,  0.7438,  0.7675, -0.0370],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2078, -0.2487, -0.4453,  1.1778, -0.6640,  0.8787, -0.4053,  0.9550],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5110, -0.3855,  0.0769, -0.8437,  0.4076,  0.9690,  0.5869, -0.1599],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8054,  1.1661, -0.4427, -0.4505,  0.3983, -0.1210,  0.6219, -0.4692],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4123, -0.1405, -0.3033,  0.7043,  0.4439, -0.4765,  1.6885, -0.7029],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4353, -0.9164, -0.9391,  0.5868,  0.4491, -0.4359, -0.0151, -0.3373],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7126,  0.4088,  0.8765,  0.4713,  0.7897,  1.0540, -1.1737, -0.1646],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1946, -0.5490,  1.3333, -0.1221,  0.6046,  0.1763, -0.6164,  0.4149],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3783, -0.0425,  0.2805,  0.5340, -0.0188,  0.2325,  0.4617,  0.6887],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2772,  0.1951, -0.0494,  0.7112,  0.4024,  0.9126, -1.2159,  0.0738],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3379,  0.7638,  0.6039,  0.8949, -0.8499,  0.8515,  1.2684, -0.3722],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3784,  0.1565, -0.6926,  0.7460,  0.0279, -0.0112,  1.2429, -1.3823],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5465, -0.4671,  0.0726,  0.1938, -0.5441,  0.3301,  0.4236, -0.3022],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0405, -0.2507, -1.4164, -0.0739,  0.9511,  0.3073, -0.3021,  0.1584],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2644, -0.4315, -1.0051, -0.3067,  0.0794,  1.0114, -0.0018, -0.3441],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6834, -0.4984,  0.0703, -0.0433,  0.7952, -1.3590,  0.0090, -0.6749],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1844,  0.1804, -0.5183, -0.4906,  0.5009, -0.3687,  0.4478, -0.5500],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6317, -0.7180,  0.6865, -0.3598, -0.1934, -1.0221,  0.5359,  0.3025],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9103, -0.3535, -0.6275,  0.0758,  0.9791,  0.0259,  0.4511, -0.0813],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2051, -0.6514, -0.9724,  1.3125,  1.6611, -0.4791, -1.5796,  0.6424],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0518, -0.0642, -0.4543,  0.5370,  0.8524, -1.5981, -0.4521, -0.5370],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4943,  0.6825, -0.6006,  0.9549, -0.4873,  0.4717,  0.8923, -0.1048],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4353, -0.9164, -0.9391,  0.5868,  0.4491, -0.4359, -0.0151, -0.3373],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2720, -0.8677, -1.0678,  0.1206,  0.0449,  0.8131, -0.6555, -0.0284],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6124, -0.7993, -0.2230,  0.3631,  0.7361, -0.1088,  0.5622, -0.0329],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5843, -0.2000, -0.4856, -0.9054, -0.1357, -1.1285,  0.3358, -0.2739],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7225, -0.2660, -1.2892,  0.5941, -1.0773,  0.3518,  0.0055, -0.3156],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9739, -0.0793, -0.5129,  0.1216, -0.2960,  0.6499, -0.3094,  1.0629],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6256,  0.7993, -1.0634, -0.0773,  0.2607,  0.0873, -1.1808,  0.6928],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.7270, -1.2305, -0.2764, -0.0516, -0.2921, -0.6588,  0.2272, -0.4309],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7124,  1.4083, -0.5349,  1.3637, -0.8642, -0.1234,  1.2757, -0.1997],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3473,  0.2054,  0.1541,  0.6007, -0.3758,  0.2887,  0.3997, -0.1929],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1596, -0.5709, -0.2223, -1.0791,  0.4195, -0.4276,  0.2384, -1.4346],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4747,  0.3603, -1.4617,  0.0285, -0.6501,  0.5266, -0.2564, -0.0544],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2359,  0.7860, -1.1697,  0.9634,  0.2602,  0.3777,  0.8401,  0.4616],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.7270, -1.2305, -0.2764, -0.0516, -0.2921, -0.6588,  0.2272, -0.4309],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6256,  0.7993, -1.0634, -0.0773,  0.2607,  0.0873, -1.1808,  0.6928],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0529,  0.5703, -0.1957,  0.5508, -1.5976,  0.1626,  0.7016, -1.1543],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7423,  1.2000,  0.6157, -0.6646,  0.0438,  0.4949,  0.3900, -1.1686],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9479,  1.5221,  1.2226,  0.7026,  0.3264, -0.1604, -0.5809, -1.7140],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7619,  0.2752, -0.9214,  0.0451,  0.2405, -0.1944,  0.3906, -0.3350],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0414, -1.3669,  0.5056,  0.5282,  0.0533,  0.3957,  0.5746,  0.7395],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9827, -1.2354, -0.2663, -0.0436,  0.4208,  0.4458,  0.3344,  0.3293],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.6220, -0.7738,  0.6050,  0.6587, -0.1942,  0.2415,  0.3897,  0.8040],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8534,  0.7193, -0.3810,  0.2350,  0.5580,  0.4505,  1.7091, -1.1263],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3152, -1.1700,  0.4870, -0.4932,  0.5180, -0.6852,  0.1619, -1.0281],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0578,  0.6440, -0.1595,  0.8692,  0.1641,  0.8108,  0.1317,  0.2230],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4205, -0.4950, -0.1104,  0.3777, -0.4970,  0.1881,  0.7171, -0.0356],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3035,  0.0279, -0.5315,  0.2731,  0.0801,  0.5186,  1.1805, -0.7179],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6171, -0.6153, -0.2723, -1.2769,  0.2883, -1.0221,  0.4630, -0.6102],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4432,  0.3017, -0.8244, -0.1214, -0.3688, -0.9504,  0.4169,  0.7998],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6171, -0.6153, -0.2723, -1.2769,  0.2883, -1.0221,  0.4630, -0.6102],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.5220, -1.0283,  0.4023,  0.4057,  0.1866, -0.2016,  0.3396,  0.5263],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3005, -0.0815, -0.9124,  0.7570, -0.2251,  0.2280,  0.5949, -0.3375],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.5009, -0.5321,  0.3047,  0.6750, -0.2400,  0.5787,  0.9845, -0.1179],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3551, -0.3811, -0.7802, -2.0192,  0.4551, -0.2596,  0.9589, -0.3982],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1649,  0.6442,  0.0705,  0.3978,  0.0217, -0.2050,  0.5143, -0.1630],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4145,  0.8610,  0.9164, -0.2274,  1.7211,  0.1274,  0.0914, -0.6842],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7124,  1.4083, -0.5349,  1.3637, -0.8642, -0.1234,  1.2757, -0.1997],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0475,  0.0810, -1.1006,  0.0088,  1.0014,  0.4808,  0.2497,  0.3705],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4123, -0.1405, -0.3033,  0.7043,  0.4439, -0.4765,  1.6885, -0.7029],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7130,  0.7493, -0.2130,  0.2987,  0.7536,  0.2563,  0.0331, -0.3810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5549, -0.7166,  0.2193,  0.3855, -0.0409,  0.2575,  0.2540,  0.1095],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4353, -0.9164, -0.9391,  0.5868,  0.4491, -0.4359, -0.0151, -0.3373],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1561, -1.0511, -0.2367, -0.7654, -0.2698,  0.3372,  0.8145, -0.7119],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.1557, -0.1547,  1.8397, -1.3330,  0.1982,  2.1752, -0.9636, -0.9388],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.2987, -0.6919, -0.4981,  0.9118,  0.8905,  0.3724, -0.4473],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2654, -0.5012, -0.2998, -0.1626, -0.0411,  0.5093,  0.4546,  0.7720],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.8221, -0.2650,  1.0105,  1.1647, -0.9558,  1.1278,  0.4897,  1.3593],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1758, -0.1411, -0.2204, -1.0582, -0.2098, -0.4604,  0.4761, -1.1206],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0931,  0.7602, -0.5286, -0.1944, -0.0664, -0.9514,  0.5077,  0.8472],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.9444, -0.6346,  0.8226,  0.3903,  0.6942,  0.5862, -0.4644,  0.5775],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4125,  0.6879, -0.3005, -0.0485, -0.9935, -0.2023,  0.0107, -0.4584],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7124,  1.4083, -0.5349,  1.3637, -0.8642, -0.1234,  1.2757, -0.1997],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5743,  0.4546,  0.0324, -0.0905,  0.1465,  0.5467,  0.8201, -0.0431],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8490, -1.9178,  0.2531,  0.2100,  0.5579,  0.0297,  0.6171,  0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0812,  1.5204, -0.2998, -0.8709, -0.4943, -0.2680, -1.6892, -0.5006],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3551, -0.3811, -0.7802, -2.0192,  0.4551, -0.2596,  0.9589, -0.3982],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2810, -0.4043,  0.0714, -0.0755, -0.1043, -0.6560,  0.3092,  0.4602],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4931, -0.4237,  0.6830, -0.5270,  0.4068, -0.0466,  0.6762,  0.5227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6956, -1.5151, -0.4141, -0.9174,  0.5976, -0.5333,  0.3555,  0.7930],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1630,  0.4466, -0.2172,  0.4694,  0.3174,  0.6545,  0.3090, -0.9887],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1536, -0.2291, -0.2095, -0.6728,  0.1844,  1.5782,  1.0557,  0.6110],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.3592, -2.5607,  0.3497, -0.0449,  0.6289,  0.1950, -0.0373,  0.7144],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3650,  0.6867,  0.1314,  0.0993, -0.9046,  0.6464,  0.9931, -1.0672],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4753,  0.7777, -1.4353,  0.5531,  0.8062, -0.4698,  0.4082,  0.1882],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5150, -1.0864, -0.3459, -0.8359,  0.4598,  0.1705,  0.5889,  0.7324],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5825, -0.0716,  1.3243,  0.2369,  1.1701,  1.1523, -0.9678,  0.1227],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7333, -0.3131, -0.1070, -1.1875,  0.4511,  0.2006,  0.6505, -0.5723],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3060,  0.2418, -1.1001, -1.4619, -0.1809, -0.4191,  0.7680,  0.1061],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5529, -0.0034, -0.2246, -1.3148,  0.1730,  1.3198,  1.6179,  0.0572],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0659, -0.7619,  0.1984,  0.0462,  0.1859,  0.3917,  0.5783,  0.5545],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6956, -1.5151, -0.4141, -0.9174,  0.5976, -0.5333,  0.3555,  0.7930],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4353, -0.9164, -0.9391,  0.5868,  0.4491, -0.4359, -0.0151, -0.3373],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8607,  0.2732, -0.3036, -0.0216,  1.1668,  0.4947,  0.4997, -0.0064],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.0906, -1.4129,  0.6801,  0.5599, -0.1634,  0.6614,  0.2262,  1.0368],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0854,  0.1809,  0.0236,  0.3132,  0.7533,  0.2521,  0.1971,  0.8808],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0850,  0.6225,  0.5681,  0.5414, -0.2247,  1.1036,  1.3498, -0.1898],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8449, -0.1048, -0.4236,  1.1299,  1.0045,  0.3844, -0.5186,  0.5756],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0116,  0.7801, -0.8342,  0.7964,  0.0905,  0.2245,  0.1796,  0.4432],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6087,  0.9192,  1.0122,  0.3771, -0.0018,  0.2077, -0.4030, -0.8874],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3464,  0.4791, -0.3365,  0.1416,  0.7265,  0.8576,  0.5639,  0.1467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6636, -0.2799, -0.5239, -0.1489,  0.8878,  1.0748,  0.5214,  0.1299],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0576, -0.2197,  0.2316, -1.5265,  0.2658,  0.6383,  1.1364, -0.0809],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3351,  0.6524, -1.0291,  0.3834,  0.1495,  0.5809,  1.1887,  0.3079],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1180, -0.0416, -0.8763, -0.2873, -0.4334, -0.7726,  0.5634, -0.9298],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8188,  0.4694, -0.6897,  0.2585, -0.8567,  0.7162,  1.1603, -0.0844],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-6.7536e-02, -3.2272e-01,  1.2348e-01, -1.5879e+00,  1.2760e-03,\n",
       "          6.2279e-01,  1.3849e+00, -1.4608e-02], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0833,  0.1087, -0.2913, -0.4963,  0.2202,  0.7638,  1.0860,  0.1592],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.5385,  0.5571,  0.5738,  0.6988,  0.3845,  0.2311,  0.4730,  0.5402],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1758, -0.1411, -0.2204, -1.0582, -0.2098, -0.4604,  0.4761, -1.1206],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2372, -0.9180, -0.3118, -0.7839, -0.0800, -0.1917,  0.5412, -0.8433],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8514, -0.2996, -0.6773, -0.0027, -1.7825,  0.0739,  1.3115, -1.1820],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3978,  0.8289,  0.0878,  0.1201, -0.1270,  0.4400,  0.3116,  0.0532],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4450, -1.0183,  0.3836,  0.1490, -0.0475,  0.9670,  0.5027,  0.8949],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9042,  0.9996,  0.3991, -1.0025,  0.3029,  0.5853,  0.2676, -0.5295],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3050, -0.2334, -0.4504,  0.1355,  0.7399,  0.5577,  0.9105, -0.1477],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4381,  0.2531, -0.5251,  0.1206,  0.5563,  0.2417, -0.2080, -0.0229],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1564, -0.4995,  1.1636,  0.4166,  0.5845, -0.4244,  0.1212, -0.4958],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7081,  0.6645, -0.6743,  0.4235, -0.8032, -0.5496,  1.4963, -2.0017],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2561, -0.5105, -0.7641, -1.3003,  0.3922,  0.3809,  0.6811, -0.2371],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1139,  0.3672, -0.3607,  0.1584, -0.0189,  0.3201,  0.2971, -0.4729],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3153, -0.8104, -0.6908,  0.3239, -0.1799,  0.5911, -0.3374, -0.8699],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4205, -0.4950, -0.1104,  0.3777, -0.4970,  0.1881,  0.7171, -0.0356],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4919, -0.8661, -0.2220, -0.8113,  0.3232,  1.2874,  0.5226,  0.0017],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0414, -1.3669,  0.5056,  0.5282,  0.0533,  0.3957,  0.5746,  0.7395],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0512,  0.3859,  0.1402,  0.8062,  1.0378, -0.4110, -0.2322,  1.0157],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0886,  0.1709, -0.0917,  0.0454, -0.9622, -0.1481,  1.0262, -0.7568],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0580, -0.7691, -0.7319,  0.1374,  0.2664,  1.6620,  0.1256,  0.0851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0117,  0.1518, -0.6014,  0.8422, -0.5187,  0.5115,  0.1055,  0.4064],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3909,  0.2347, -0.9099, -0.0508, -0.1404,  0.5952,  0.7900, -1.1816],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3064,  0.1378,  2.1686, -1.1119,  0.3434, -0.2551,  0.0605, -1.1142],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2036,  0.2442, -0.7671, -1.6811, -0.4280, -0.2721,  0.3065,  0.5537],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8821, -0.5503, -0.2304, -0.5340,  0.9733, -0.5774,  0.3891,  0.4357],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1409, -1.0835,  0.7435,  0.2078, -0.0453, -2.5472, -0.5286, -1.0340],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6171, -0.6153, -0.2723, -1.2769,  0.2883, -1.0221,  0.4630, -0.6102],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2078, -0.2487, -0.4453,  1.1778, -0.6640,  0.8787, -0.4053,  0.9550],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7225, -0.2660, -1.2892,  0.5941, -1.0773,  0.3518,  0.0055, -0.3156],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4307,  0.4307, -0.6501,  0.9811,  1.0341,  0.3277, -0.1172,  0.3481],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3464,  0.4791, -0.3365,  0.1416,  0.7265,  0.8576,  0.5639,  0.1467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2034, -0.4932,  0.0616, -1.0489,  0.1587,  0.7716,  0.3113, -0.7788],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3353, -0.5763,  0.3301, -0.9893, -0.0142, -0.4339,  0.7470, -0.3544],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6821,  0.2081, -0.0504, -0.0033, -0.7715, -0.4684,  0.1333, -0.8185],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1794, -1.5753, -0.1606, -0.5397,  0.6700, -0.6693,  0.4436, -0.5099],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2331,  1.2460, -0.7103,  0.4080,  0.0818,  0.3889, -0.6004,  0.0031],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 5.1618e-05, -9.2661e-01, -4.3573e-02, -8.1513e-01,  7.2447e-02,\n",
       "          1.5581e+00,  6.6882e-01, -1.3828e+00], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0860,  0.0579, -0.3718,  0.4040,  0.0790,  0.2088,  0.1766,  0.1416],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2814,  1.2469,  0.0509,  1.1947,  0.4922,  0.4428, -0.0463, -0.6036],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2720, -0.8677, -1.0678,  0.1206,  0.0449,  0.8131, -0.6555, -0.0284],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4074, -0.5744, -0.0026, -1.5637, -0.0780,  0.0571,  0.5171, -0.9459],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3706, -0.3424, -0.1833, -0.9579, -0.0152,  0.2029,  0.8025,  0.1876],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7124,  1.4083, -0.5349,  1.3637, -0.8642, -0.1234,  1.2757, -0.1997],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1435,  0.4549, -0.5204, -0.7785,  1.1455, -0.9636,  0.6023,  0.2964],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6359,  0.2194,  0.2061,  0.0474, -0.7514,  0.0932,  0.6091, -0.5248],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9235, -1.0276, -0.0807, -0.9887,  0.3858,  0.8386,  0.7292, -0.1143],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6540, -0.5051,  0.3050, -0.2827, -0.2985,  1.0085, -0.1336, -1.0482],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0350,  0.6478,  0.3367, -0.9109,  0.3947,  0.6719,  0.2571, -0.8745],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1164, -0.8852,  0.1694, -0.7867,  0.5945,  0.6899,  0.6900, -0.4798],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0998, -0.5310, -0.5572, -1.0556,  0.3052,  1.2023,  0.6475, -0.7915],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8514, -0.2996, -0.6773, -0.0027, -1.7825,  0.0739,  1.3115, -1.1820],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8514, -0.2996, -0.6773, -0.0027, -1.7825,  0.0739,  1.3115, -1.1820],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4244, -0.9223, -0.9525,  0.5882,  0.1975,  0.5657,  0.0513,  0.6586],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2549,  1.3792,  0.1371,  0.2329,  1.7248, -0.6655,  0.4562, -0.2789],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1932, -0.3039, -0.9312,  0.3338, -1.1831,  1.4272,  0.2136,  0.1681],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1175,  0.2820,  0.7928,  0.6246, -0.4058, -0.7139,  0.7685, -0.6326],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1005, -0.7831,  0.1407, -0.4790,  0.2391,  0.1131,  0.6162, -0.2052],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4074, -0.5744, -0.0026, -1.5637, -0.0780,  0.0571,  0.5171, -0.9459],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2359,  0.7860, -1.1697,  0.9634,  0.2602,  0.3777,  0.8401,  0.4616],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5554,  0.2858, -0.1516, -0.8961,  0.7511,  0.5517,  0.8937, -0.4454],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0686, -0.0073,  0.7047, -0.1226,  0.0790, -0.3185, -1.9402,  0.3766],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3092, -1.5508,  0.0045,  0.7535,  0.4601,  0.3624,  0.6851,  0.7760],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0578,  0.6440, -0.1595,  0.8692,  0.1641,  0.8108,  0.1317,  0.2230],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0890,  0.3440, -0.0060,  0.0154, -0.9420,  0.7756,  0.6387,  0.3499],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7905,  0.3440, -0.6582,  0.6176, -0.2314, -0.3067, -0.0254,  0.5787],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0660, -0.7044, -0.4425,  0.0610, -0.8088,  1.6181, -0.6597, -1.4024],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6037,  0.3266, -0.8499, -0.5683, -1.3553,  0.2487,  1.0496, -0.9207],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7255,  0.1336, -0.7817,  0.8739, -0.0754,  1.3320, -0.0857, -0.4478],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2548,  0.3619, -0.6159, -0.9033, -0.3719,  1.0008,  0.9217, -0.0242],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2548,  0.3619, -0.6159, -0.9033, -0.3719,  1.0008,  0.9217, -0.0242],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1931,  0.1768,  0.5459, -0.2530,  0.4202,  0.9322,  0.1465,  0.4862],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1913, -0.2242, -0.0886, -0.2805,  0.2356,  0.0833,  0.7776, -0.4166],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6956, -1.5151, -0.4141, -0.9174,  0.5976, -0.5333,  0.3555,  0.7930],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3783, -0.0425,  0.2805,  0.5340, -0.0188,  0.2325,  0.4617,  0.6887],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3403, -0.6657, -0.0482,  0.4301,  0.1179,  0.3042,  1.2318, -0.8565],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6124, -0.7993, -0.2230,  0.3631,  0.7361, -0.1088,  0.5622, -0.0329],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1009, -0.7495, -0.1195,  0.8707, -0.0161,  0.0894, -0.0936,  0.6522],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1719,  0.1985, -0.8608,  0.4886,  0.4269,  0.0613, -0.2333,  0.4714],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.7642, -0.6409,  0.8334,  0.2247,  0.1160,  1.0308,  0.5037,  0.8574],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3137, -0.7152, -0.1236, -0.6345,  0.1884, -0.0475,  0.2554, -0.8724],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3127,  0.6347, -0.1103, -0.5412, -0.6290,  0.4996,  0.2813, -0.3601],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1090,  0.0643, -1.0708, -1.0574,  0.8868, -0.3894,  0.5141, -0.2788],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3380, -0.4844, -0.4456, -0.5468, -0.2307, -1.7738,  0.2372, -0.5795],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4797, -1.0395,  0.3259, -0.3762,  0.0057,  0.6884,  0.5406,  0.1351],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0560, -1.5350,  1.7092,  0.6257,  0.6523, -0.3689, -2.1913,  1.2538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1536, -0.2291, -0.2095, -0.6728,  0.1844,  1.5782,  1.0557,  0.6110],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6794,  1.0922, -1.0491,  0.8857,  0.6785, -0.1178,  1.0627, -1.2336],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6850, -0.4306,  0.6483, -0.4717,  0.5044, -0.0354,  0.4706, -0.8866],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3717,  0.2809,  0.5501,  1.1542,  0.8045, -0.4331,  0.2620, -0.7621],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8599,  0.2354, -0.3578, -0.0137, -0.3834,  0.7703, -0.6729, -0.8917],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6944, -0.9547, -0.2049,  0.7023,  0.5913,  0.3684,  0.5741,  0.4554],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1536, -0.2291, -0.2095, -0.6728,  0.1844,  1.5782,  1.0557,  0.6110],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5489,  0.5379, -0.3404,  0.5889, -1.0600,  0.1846,  1.0943, -0.4105],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4761, -1.1731,  0.4360,  0.1572,  0.2620,  0.2117,  0.3364,  0.2662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9827, -1.2354, -0.2663, -0.0436,  0.4208,  0.4458,  0.3344,  0.3293],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0931,  0.7602, -0.5286, -0.1944, -0.0664, -0.9514,  0.5077,  0.8472],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1536, -0.2291, -0.2095, -0.6728,  0.1844,  1.5782,  1.0557,  0.6110],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0457, -1.1814,  0.4453, -0.0559,  0.7198,  0.6637,  0.4503,  0.1145],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3790, -0.4321,  0.0920,  0.2057,  0.1023, -0.4515,  0.3956,  0.6333],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1643, -0.2651,  0.2782,  0.0140, -0.3154, -0.9191, -0.0686,  1.6428],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5853, -1.5349, -0.0752,  0.1858,  0.4608,  0.5738,  0.4532,  0.3148],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2826,  0.6226, -0.4657, -1.0431,  0.2896, -0.4032,  0.3564,  0.2762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7126,  0.4088,  0.8765,  0.4713,  0.7897,  1.0540, -1.1737, -0.1646],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2172,  1.1201, -1.4705,  0.1661,  1.6616, -0.0130,  0.6954,  0.7796],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3098,  0.1479, -0.4650, -1.1712, -0.0665,  0.0728,  0.5201, -0.6443],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0812,  1.5204, -0.2998, -0.8709, -0.4943, -0.2680, -1.6892, -0.5006],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8792,  0.6708, -0.6291, -0.0271, -0.5904,  0.8283,  1.3314, -0.7615],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1109,  0.0091, -0.8253,  0.2503,  0.8877,  0.4365,  0.0260, -0.1730],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7591,  0.5419,  0.3871, -0.0180,  0.0781,  1.0203,  0.2045,  0.6810],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0544, -0.7764, -0.2172, -0.7911,  0.2605, -1.9044,  0.1099, -0.0812],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4399, -0.8980, -0.3085, -1.5991,  0.4030,  0.8695,  0.5794, -1.1378],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0618, -0.0301, -0.7451, -0.1414,  0.4228,  1.1501,  0.5944, -0.3588],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3180, -0.4839,  0.5259,  0.0888, -0.2746,  0.9000,  0.0847,  0.2303],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7243, -0.5485,  0.5957, -0.5980,  0.3749, -0.9390,  0.0554, -0.6237],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0251,  0.0276, -1.0300,  1.1368,  0.5535,  0.3050,  0.2366,  0.0847],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5496, -1.1077, -0.4035, -1.3611,  0.5131, -0.1081,  0.6268, -0.0274],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0578,  0.6440, -0.1595,  0.8692,  0.1641,  0.8108,  0.1317,  0.2230],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1994, -0.1673, -0.8343,  0.7906,  0.2932,  0.6294,  0.2727,  0.8184],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2036,  0.2442, -0.7671, -1.6811, -0.4280, -0.2721,  0.3065,  0.5537],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4972,  0.6143, -0.4224,  0.4790,  0.6695, -0.7599,  0.6204,  0.1398],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0848, -0.2832, -0.7531, -0.5848,  0.9193, -0.9684, -0.0859,  0.1515],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2549,  1.3792,  0.1371,  0.2329,  1.7248, -0.6655,  0.4562, -0.2789],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5191,  0.1084, -0.3531,  0.1243,  0.5557,  0.3017,  0.4235,  0.1526],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2786, -0.7574, -0.7846,  0.6534,  0.4338,  0.2344, -0.7515, -0.3658],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1018,  0.0904, -0.5801,  0.0327,  0.1376,  0.1780,  0.4352, -0.0639],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 2.0122, -0.2611,  0.0053, -0.2846, -0.0467,  0.9147, -0.1513,  0.7409],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5234,  0.0338, -0.7251,  1.2678, -0.0100,  0.3575, -0.1512,  0.0923],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2308, -0.5720, -1.4367,  0.2303,  1.7991, -0.6680,  1.1076, -0.3021],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3789, -0.7382, -0.1070,  0.2132,  0.8643,  0.7968, -0.0259, -0.7949],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3551, -0.3811, -0.7802, -2.0192,  0.4551, -0.2596,  0.9589, -0.3982],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8025,  0.8540, -0.6958,  0.3891, -0.3938,  1.0374,  1.0846,  0.4643],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2018, -0.6950, -0.6298,  0.5120, -0.0503, -0.0852, -0.5678, -0.1327],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4161,  0.1518, -1.3122,  1.0894,  1.7056, -0.5640, -0.9776,  0.3012],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5489,  0.5379, -0.3404,  0.5889, -1.0600,  0.1846,  1.0943, -0.4105],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7657,  0.2451,  0.1183,  0.4657, -0.3882,  1.0398,  1.3488, -0.1524],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4271, -0.3672, -0.0837, -0.3126, -0.1948, -0.0670,  0.6191,  1.1155],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1176,  0.4218, -0.3402,  0.4371, -0.5598,  0.4696,  0.5705,  0.6694],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4450, -1.0183,  0.3836,  0.1490, -0.0475,  0.9670,  0.5027,  0.8949],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5692,  0.8034, -1.0208,  0.4591,  0.5872,  1.8799,  1.2861,  0.3538],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3423, -0.8841,  0.3880,  0.1075, -0.2469,  1.0622,  0.2396,  0.3759],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5175, -0.0045, -0.6302, -0.0285,  0.1000,  0.3553,  0.3166,  0.4662],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.7056,  0.3941,  0.8665,  0.2108, -1.5410, -0.9368,  1.2490, -0.0177],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4134, -0.1186,  0.1028, -1.0502,  0.8227,  0.4123,  0.5102,  0.1311],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6466, -1.6326, -0.0464,  0.0080, -0.0899,  0.9066, -0.3485, -0.3440],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0681, -0.4543, -0.3530,  0.9673,  1.2640,  0.3050, -0.5489, -0.3783],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-3.5068e-04, -3.5577e-01, -4.3289e-02,  7.9474e-01,  1.0655e+00,\n",
       "          6.9698e-01, -3.3529e-02, -8.8864e-01], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0512,  0.3859,  0.1402,  0.8062,  1.0378, -0.4110, -0.2322,  1.0157],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0518, -0.0642, -0.4543,  0.5370,  0.8524, -1.5981, -0.4521, -0.5370],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.3853,  0.2094, -0.3159, -0.4351,  1.5092,  0.4876,  0.9173,  0.1747],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5564,  0.6100, -0.4854,  0.8716,  0.2565,  1.0758, -1.5917, -0.1780],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7445, -0.2623,  0.1395, -0.5855, -0.1425,  1.1495,  0.9049,  0.1007],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.8821, -0.5503, -0.2304, -0.5340,  0.9733, -0.5774,  0.3891,  0.4357],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2529,  1.0850, -0.6464,  0.4394, -0.8751,  0.0660,  1.1247, -0.7863],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4123, -0.1405, -0.3033,  0.7043,  0.4439, -0.4765,  1.6885, -0.7029],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-2.3592, -2.5607,  0.3497, -0.0449,  0.6289,  0.1950, -0.0373,  0.7144],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4248, -0.2675, -0.0400,  0.1660, -0.2595, -0.4632,  0.0136, -0.4993],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1677,  0.5964, -0.1136,  0.8168,  0.0585,  0.8345, -0.2508, -0.8699],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0947,  0.0997, -0.9026, -0.0582, -1.2131, -1.5125,  0.4917, -1.5762],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5489,  0.5379, -0.3404,  0.5889, -1.0600,  0.1846,  1.0943, -0.4105],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7991,  0.9565, -1.0042, -0.3530,  0.1640,  0.0343, -0.2555,  0.0979],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3464,  0.4791, -0.3365,  0.1416,  0.7265,  0.8576,  0.5639,  0.1467],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1858,  0.3943, -0.3495,  0.0982,  0.2488,  0.3967,  0.7914, -0.2744],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2156, -0.4564, -0.2897,  0.2586,  0.1285,  0.6006, -0.0382, -0.1044],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6124, -0.7993, -0.2230,  0.3631,  0.7361, -0.1088,  0.5622, -0.0329],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6070,  0.4961, -0.8357, -1.3912,  0.9585,  0.6827,  1.4679, -0.0346],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9871, -0.7945, -0.3856,  0.8210,  0.6435,  0.6205,  0.2255,  0.6106],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6189,  0.3264,  0.1408, -0.0904,  0.3855, -0.2438,  0.8559, -0.5226],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2951,  0.1601, -1.0466,  1.4997,  1.1596,  0.2834, -0.5456,  0.5746],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3231, -0.4755, -0.8249,  0.6549, -0.0607, -0.2026, -0.1340, -0.2698],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4216, -0.2748, -0.5793, -0.5038,  0.4880,  0.9283,  0.5490, -0.5896],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9235, -1.0276, -0.0807, -0.9887,  0.3858,  0.8386,  0.7292, -0.1143],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0821,  0.2587, -0.4527,  0.3917, -1.3008,  0.1477,  1.1667, -0.6677],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5583,  0.1613,  0.9095, -0.1930,  0.5146, -0.6232,  0.4456,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2548,  0.3619, -0.6159, -0.9033, -0.3719,  1.0008,  0.9217, -0.0242],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0631,  0.1863, -0.0329,  0.9144, -0.0103, -0.3952,  0.0064,  0.1046],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5509,  0.3074,  0.3618,  0.4470,  0.1485, -0.0068, -0.2737, -0.7040],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2352, -0.4548, -0.5176,  0.4208,  0.3552,  0.5927,  0.9071, -0.3089],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-6.7536e-02, -3.2272e-01,  1.2348e-01, -1.5879e+00,  1.2760e-03,\n",
       "          6.2279e-01,  1.3849e+00, -1.4608e-02], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4416, -0.6882,  0.1805, -1.0204,  0.1494, -0.9023,  0.3204, -1.3511],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6200,  0.7120,  0.4936,  0.6340, -0.1986,  0.5371,  0.4448,  0.1392],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1872, -0.3509, -1.5394, -0.2995,  0.0970, -0.3160, -0.2760,  0.7112],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2696,  0.3164,  0.8018,  0.0516, -0.3299,  0.5758, -0.2250, -0.0608],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6636, -0.2799, -0.5239, -0.1489,  0.8878,  1.0748,  0.5214,  0.1299],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.5235,  0.6352, -0.9207, -0.7687,  0.5164,  2.7138,  2.0839,  0.2009],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.2524, -1.4836,  0.7817,  0.8800,  0.6740, -0.1755,  0.3902,  1.0222],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.1946, -0.5490,  1.3333, -0.1221,  0.6046,  0.1763, -0.6164,  0.4149],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9679, -0.4694, -1.1779, -1.7899,  0.5662, -1.2617,  0.7484,  0.8717],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9103, -0.3535, -0.6275,  0.0758,  0.9791,  0.0259,  0.4511, -0.0813],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0931,  0.7602, -0.5286, -0.1944, -0.0664, -0.9514,  0.5077,  0.8472],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4626,  0.2965, -1.3869,  1.5136, -0.9463,  1.1611, -0.0701,  0.1160],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0154, -0.4618,  0.1087,  0.6029,  0.4105,  1.4100, -0.0379],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1098, -0.4916, -0.0283, -0.0240,  0.0149, -0.0883,  0.1747,  0.1043],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1455, -1.0081,  0.7713,  0.7106,  0.1620, -0.1807,  0.5099,  0.7030],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.2198,  0.4079, -1.2334, -1.1619,  1.0696, -0.3194,  1.2574,  1.2354],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2034, -0.4932,  0.0616, -1.0489,  0.1587,  0.7716,  0.3113, -0.7788],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7563,  0.5432, -0.1227, -1.0078,  1.0344,  0.0385,  0.8128, -0.9735],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0027,  0.4874, -0.0727,  0.3799,  0.3991,  0.3723,  0.6148,  0.2105],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0660,  0.5274, -1.2773,  0.4040,  0.2685, -1.0807,  0.0581, -0.8081],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4228, -0.1349, -0.2533, -0.1180,  0.3189, -0.2529,  0.3764, -0.7318],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4728, -0.6804, -0.1900,  1.5283,  0.6559,  0.0544,  0.8665,  0.9868],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0736, -0.6401, -0.6863,  0.2150, -0.7141,  0.4187,  0.2122, -0.9739],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8469, -0.4289,  0.2474, -0.2420, -0.5734,  0.0396,  0.2738, -0.4354],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1914,  0.3464,  0.3271, -0.2038, -1.1890,  0.9226,  0.1772,  0.7975],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7243, -0.5485,  0.5957, -0.5980,  0.3749, -0.9390,  0.0554, -0.6237],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0153,  0.5839, -0.6581,  0.3285, -0.1006,  0.3831,  0.5810, -0.1445],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0818, -0.6709,  0.4617, -0.2762, -0.1546,  0.4194, -0.2362, -0.1448],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5100, -0.2623, -0.0806, -0.2032,  0.4844, -0.2058,  0.8236, -0.2506],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6682,  1.2260, -0.1669,  0.8900,  0.2104, -0.6523,  0.2708,  0.2245],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-6.7536e-02, -3.2272e-01,  1.2348e-01, -1.5879e+00,  1.2760e-03,\n",
       "          6.2279e-01,  1.3849e+00, -1.4608e-02], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2737, -0.6579, -0.5788,  0.6993, -0.2087, -0.9587, -0.9145, -0.2417],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0637,  0.3394, -0.7517, -0.2808,  0.5011,  0.8942,  0.8288, -0.5807],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.7630, -0.0559, -0.1887,  0.9473,  0.3064, -0.7506, -0.0202, -0.2636],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5144, -0.9448, -0.1103, -0.0298,  0.2326,  0.5350,  0.8177, -0.7735],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3048, -0.3602, -1.5773,  0.2471, -0.7855,  0.2147, -0.3935,  0.3826],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6237, -1.4505,  1.0485, -0.0572,  1.2005,  0.2882, -0.1553, -0.2524],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4248, -0.2675, -0.0400,  0.1660, -0.2595, -0.4632,  0.0136, -0.4993],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6087,  0.9192,  1.0122,  0.3771, -0.0018,  0.2077, -0.4030, -0.8874],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.1183, -0.0451, -0.4966, -0.2189, -0.1366,  0.2808,  1.1144, -0.5037],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.4340, -0.5934,  0.2837, -0.4491,  0.0660,  0.7862, -0.1178, -0.3341],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0579,  0.1730, -0.3503,  0.6253,  0.1982,  1.0946,  0.1296,  0.1770],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3851,  0.9717, -1.1209,  1.6869,  0.6580,  1.0459,  0.4883,  0.5068],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2636,  0.0118,  0.2097, -1.0985,  0.0071,  0.6591,  0.4722, -0.8645],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6011,  0.8008, -0.2436, -0.2412,  0.6215,  0.5993,  0.7707,  0.7691],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1222, -0.4371,  0.2138, -0.1137,  0.7320, -1.0298,  0.1943, -0.4297],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2057, -0.2610, -0.2960, -1.4606,  0.2642,  1.1604,  1.1125, -0.5286],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3222, -0.3985, -0.6118, -0.9861,  0.2228,  0.4828,  0.7836, -0.6197],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.3783, -0.0425,  0.2805,  0.5340, -0.0188,  0.2325,  0.4617,  0.6887],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.9879, -0.2471,  0.4005,  0.2460, -0.3857,  1.3530,  0.7727,  0.9851],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4865,  0.0344, -0.3096,  0.1346,  0.9766,  0.0055,  1.3029, -0.2641],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2564, -1.3949,  0.0701, -0.3588,  0.4067,  0.8866,  0.5092,  0.6627],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0253, -0.6406, -0.7284, -0.2093,  0.2576,  1.2301,  0.0510,  0.0585],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0812,  1.5204, -0.2998, -0.8709, -0.4943, -0.2680, -1.6892, -0.5006],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2577, -0.2929, -0.3825, -2.2485,  0.3441,  0.7425,  1.1694, -1.6682],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0914,  0.4584, -0.2083,  0.1458, -0.2338,  0.1426,  0.4834,  0.1778],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3448,  0.3723,  0.4798,  0.3116,  1.2095, -0.0396, -0.0041,  0.1493],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4450, -1.0183,  0.3836,  0.1490, -0.0475,  0.9670,  0.5027,  0.8949],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.1451,  0.2217, -0.3518, -0.6551,  0.5990,  0.8192,  0.7657, -0.4583],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0373,  0.9551, -1.6521,  0.8662,  1.7502, -0.6489, -0.3755, -0.0400],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1871, -0.3822, -0.2712,  0.2698,  0.5150, -0.2466, -0.4706,  1.0804],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2372, -0.9180, -0.3118, -0.7839, -0.0800, -0.1917,  0.5412, -0.8433],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2216,  0.1013, -0.9264,  0.9121,  0.4622,  1.3540,  0.3069,  0.2959],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1886, -0.8428, -0.8355,  0.3621,  0.3577,  0.6131,  0.0552, -0.1261],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5384,  1.0775, -0.4755, -0.7933,  1.0318, -0.3885,  1.5654, -0.1587],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " ...]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tensor = zx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "55c8d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get embeddings\n",
    "res_tensor = zx()  # or zx.forward()\n",
    "# res_np = res_tensor.detach().cpu().numpy()  # ensure it's a NumPy array\n",
    "\n",
    "# Step 2: Convert to DataFrame\n",
    "embedding_dim = res_np.shape[1]\n",
    "emb_df = pd.DataFrame(res_tensor, columns=[f'theme_emb_{i}' for i in range(embedding_dim)])\n",
    "\n",
    "# Step 3: Concatenate\n",
    "assert isinstance(df_final, pd.DataFrame), \"df_final must be a DataFrame\"\n",
    "assert df_final.shape[0] == emb_df.shape[0], \"Row count mismatch between df_final and embeddings\"\n",
    "\n",
    "df_final_v1 = pd.concat([df_final.reset_index(drop=True), emb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "edcc972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>...</th>\n",
       "      <th>grade_emb_2</th>\n",
       "      <th>grade_emb_3</th>\n",
       "      <th>theme_emb_0</th>\n",
       "      <th>theme_emb_1</th>\n",
       "      <th>theme_emb_2</th>\n",
       "      <th>theme_emb_3</th>\n",
       "      <th>theme_emb_4</th>\n",
       "      <th>theme_emb_5</th>\n",
       "      <th>theme_emb_6</th>\n",
       "      <th>theme_emb_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.0544, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.7764, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.2172, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.7911, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.2605, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.9044, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1099, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0812, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.5150, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.0864, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3459, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.8359, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4598, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1705, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.5889, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7324, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.2772, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1951, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0494, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7112, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4024, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.9126, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2159, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0738, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1455, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.0081, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7713, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7106, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1620, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1807, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.5099, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7030, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7255, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1336, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.7817, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.8739, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0754, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.3320, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0857, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.4478, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count                                 reading_skill_name  \\\n",
       "0                 0.42  Making Inferences, Illustrations or other Visu...   \n",
       "1                 0.62  Illustrations or other Visual Elements, Fact a...   \n",
       "2                 0.62  Making Inferences, Illustrations or other Visu...   \n",
       "3                 0.26                                               None   \n",
       "4                 0.10                                               None   \n",
       "\n",
       "                                theme_name  ...  \\\n",
       "0                  Fun Science, Technology  ...   \n",
       "1  History, Technology, Places of Interest  ...   \n",
       "2  Sports & Games, Fitness, Healthy Habits  ...   \n",
       "3    Emotions & Feelings, Family & Friends  ...   \n",
       "4     Funny Stories, Our Friends in Nature  ...   \n",
       "\n",
       "                                  grade_emb_2  \\\n",
       "0   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_3  \\\n",
       "0  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.4681, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.4681, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_0  \\\n",
       "0   tensor(1.0544, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.5150, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.2772, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.1455, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.7255, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_1  \\\n",
       "0  tensor(-0.7764, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.0864, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.1951, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-1.0081, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.1336, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_2  \\\n",
       "0  tensor(-0.2172, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.3459, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.0494, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.7713, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.7817, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_3  \\\n",
       "0  tensor(-0.7911, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.8359, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.7112, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.7106, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.8739, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_4  \\\n",
       "0   tensor(0.2605, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.4598, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.4024, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.1620, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.0754, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_5  \\\n",
       "0  tensor(-1.9044, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.1705, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.9126, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.1807, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(1.3320, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_6  \\\n",
       "0   tensor(0.1099, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.5889, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-1.2159, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.5099, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.0857, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  theme_emb_7  \n",
       "0  tensor(-0.0812, grad_fn=<UnbindBackward0>)  \n",
       "1   tensor(0.7324, grad_fn=<UnbindBackward0>)  \n",
       "2   tensor(0.0738, grad_fn=<UnbindBackward0>)  \n",
       "3   tensor(0.7030, grad_fn=<UnbindBackward0>)  \n",
       "4  tensor(-0.4478, grad_fn=<UnbindBackward0>)  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b65acba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "022d43ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theme_emb_0</th>\n",
       "      <th>theme_emb_1</th>\n",
       "      <th>theme_emb_2</th>\n",
       "      <th>theme_emb_3</th>\n",
       "      <th>theme_emb_4</th>\n",
       "      <th>theme_emb_5</th>\n",
       "      <th>theme_emb_6</th>\n",
       "      <th>theme_emb_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.478647</td>\n",
       "      <td>-0.232980</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>0.490679</td>\n",
       "      <td>-0.868217</td>\n",
       "      <td>1.352461</td>\n",
       "      <td>1.851667</td>\n",
       "      <td>-0.927268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.338558</td>\n",
       "      <td>0.293770</td>\n",
       "      <td>-0.080786</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>-0.597078</td>\n",
       "      <td>1.113300</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>-0.262956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.937208</td>\n",
       "      <td>0.260429</td>\n",
       "      <td>-0.212252</td>\n",
       "      <td>-1.012132</td>\n",
       "      <td>-0.591905</td>\n",
       "      <td>0.556993</td>\n",
       "      <td>-0.057744</td>\n",
       "      <td>-0.263714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.707266</td>\n",
       "      <td>-1.363771</td>\n",
       "      <td>-0.045674</td>\n",
       "      <td>-0.579151</td>\n",
       "      <td>1.561574</td>\n",
       "      <td>0.197671</td>\n",
       "      <td>-1.631947</td>\n",
       "      <td>-0.674348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.452168</td>\n",
       "      <td>0.429928</td>\n",
       "      <td>1.205995</td>\n",
       "      <td>-1.176528</td>\n",
       "      <td>-0.571090</td>\n",
       "      <td>-0.011463</td>\n",
       "      <td>0.447645</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12186</th>\n",
       "      <td>0.490188</td>\n",
       "      <td>-0.334432</td>\n",
       "      <td>0.615725</td>\n",
       "      <td>0.768195</td>\n",
       "      <td>0.462333</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.276157</td>\n",
       "      <td>0.036429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12187</th>\n",
       "      <td>-0.893478</td>\n",
       "      <td>0.791431</td>\n",
       "      <td>0.534415</td>\n",
       "      <td>-0.265971</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>0.743669</td>\n",
       "      <td>0.463191</td>\n",
       "      <td>0.911320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12188</th>\n",
       "      <td>0.308778</td>\n",
       "      <td>0.773680</td>\n",
       "      <td>0.946150</td>\n",
       "      <td>-1.138530</td>\n",
       "      <td>-0.755129</td>\n",
       "      <td>0.959309</td>\n",
       "      <td>0.937776</td>\n",
       "      <td>-0.008977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12189</th>\n",
       "      <td>-0.213463</td>\n",
       "      <td>0.370834</td>\n",
       "      <td>-0.079681</td>\n",
       "      <td>0.197614</td>\n",
       "      <td>-0.762243</td>\n",
       "      <td>0.633594</td>\n",
       "      <td>0.255516</td>\n",
       "      <td>-0.205568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>-0.452168</td>\n",
       "      <td>0.429928</td>\n",
       "      <td>1.205995</td>\n",
       "      <td>-1.176528</td>\n",
       "      <td>-0.571090</td>\n",
       "      <td>-0.011463</td>\n",
       "      <td>0.447645</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12191 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       theme_emb_0  theme_emb_1  theme_emb_2  theme_emb_3  theme_emb_4  \\\n",
       "0         1.478647    -0.232980     0.972367     0.490679    -0.868217   \n",
       "1         0.338558     0.293770    -0.080786     0.689703    -0.597078   \n",
       "2         0.937208     0.260429    -0.212252    -1.012132    -0.591905   \n",
       "3         1.707266    -1.363771    -0.045674    -0.579151     1.561574   \n",
       "4        -0.452168     0.429928     1.205995    -1.176528    -0.571090   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "12186     0.490188    -0.334432     0.615725     0.768195     0.462333   \n",
       "12187    -0.893478     0.791431     0.534415    -0.265971     0.030795   \n",
       "12188     0.308778     0.773680     0.946150    -1.138530    -0.755129   \n",
       "12189    -0.213463     0.370834    -0.079681     0.197614    -0.762243   \n",
       "12190    -0.452168     0.429928     1.205995    -1.176528    -0.571090   \n",
       "\n",
       "       theme_emb_5  theme_emb_6  theme_emb_7  \n",
       "0         1.352461     1.851667    -0.927268  \n",
       "1         1.113300     0.900955    -0.262956  \n",
       "2         0.556993    -0.057744    -0.263714  \n",
       "3         0.197671    -1.631947    -0.674348  \n",
       "4        -0.011463     0.447645     0.001398  \n",
       "...            ...          ...          ...  \n",
       "12186     0.691781     0.276157     0.036429  \n",
       "12187     0.743669     0.463191     0.911320  \n",
       "12188     0.959309     0.937776    -0.008977  \n",
       "12189     0.633594     0.255516    -0.205568  \n",
       "12190    -0.011463     0.447645     0.001398  \n",
       "\n",
       "[12191 rows x 8 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a35cdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5315, -0.2869,  0.0507,  0.4116], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2076, -0.6287,  0.4181, -0.3511], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6502, -0.1750,  0.4896,  0.1439], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5282,  0.5490, -0.0987,  0.0625], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2101, -1.4079,  1.0768, -0.3018], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2925,  0.3948, -0.2723,  0.2808], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0562, -0.4544,  0.3491,  0.7652], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8897,  0.5270,  0.3686, -0.6450], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0719,  0.4008, -0.0714,  1.9966], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([0.5738, 0.7527, 0.0035, 0.2032], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([0.5738, 0.7527, 0.0035, 0.2032], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2076, -0.6287,  0.4181, -0.3511], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0562, -0.4544,  0.3491,  0.7652], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2925,  0.3948, -0.2723,  0.2808], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0309, -0.2528,  0.1525,  0.3767], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3100, -0.2842, -0.0980,  0.4679], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2101, -1.4079,  1.0768, -0.3018], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2541, -0.7695,  0.4429,  0.4659], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2101, -1.4079,  1.0768, -0.3018], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3260, 0.0497, 0.2002, 0.7067], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0719,  0.4008, -0.0714,  1.9966], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.9566,  0.7039,  0.2133, -0.2335], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8897,  0.5270,  0.3686, -0.6450], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2101, -1.4079,  1.0768, -0.3018], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5180, -0.5276,  0.6637,  0.1102], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5282,  0.5490, -0.0987,  0.0625], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3744, -0.3897, -0.0650,  0.5572], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2076, -0.6287,  0.4181, -0.3511], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6052, -0.5866, -0.1457,  0.1379], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0606, -0.1006,  0.1444, -0.0026], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0113,  0.7186, -0.0983,  0.2382], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.8897,  0.5270,  0.3686, -0.6450], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6891,  0.2793, -0.3635,  0.0887], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2838,  0.4161, -0.1460, -0.0918], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0309, -0.2528,  0.1525,  0.3767], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3260, 0.0497, 0.2002, 0.7067], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0990,  0.3674,  0.0638, -0.5285], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6361, -0.6799,  0.2654, -0.2987], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0719,  0.4008, -0.0714,  1.9966], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6052, -0.5866, -0.1457,  0.1379], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.5180, -0.5276,  0.6637,  0.1102], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0562, -0.4544,  0.3491,  0.7652], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2925,  0.3948, -0.2723,  0.2808], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6052, -0.5866, -0.1457,  0.1379], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2925,  0.3948, -0.2723,  0.2808], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2838,  0.4161, -0.1460, -0.0918], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2101, -1.4079,  1.0768, -0.3018], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1641, -1.6832,  0.7132,  0.4041], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5315, -0.2869,  0.0507,  0.4116], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5282,  0.5490, -0.0987,  0.0625], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2925,  0.3948, -0.2723,  0.2808], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3744, -0.3897, -0.0650,  0.5572], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1529, -0.3870, -0.2137,  0.6135], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6052, -0.5866, -0.1457,  0.1379], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5282,  0.5490, -0.0987,  0.0625], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7610, -0.5400, -0.1208, -0.1521], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5315, -0.2869,  0.0507,  0.4116], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.2821, -0.1033,  0.2931, -0.0589], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6052, -0.5866, -0.1457,  0.1379], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0948,  0.3161, -0.4104,  0.1100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5282,  0.5490, -0.0987,  0.0625], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6361, -0.6799,  0.2654, -0.2987], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0410, -1.0720,  0.3952,  0.1359], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0105, -0.7235, -0.3632,  0.3185], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0562, -0.4544,  0.3491,  0.7652], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.6477,  0.6042, -0.1691,  0.0945], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([0.3155, 0.6001, 0.0540, 0.0100], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([0.4259, 1.0497, 0.3486, 0.4206], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0102, -0.9552, -0.0982,  0.4072], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1666, -0.9041,  0.0545,  0.3547], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.3557, -0.4031,  0.0967, -0.3326], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.3180, -0.1791,  0.7127,  0.0594], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4481, -0.6894, -0.2614,  0.2835], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([0.7581, 1.0538, 0.1256, 0.5050], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.0623,  0.4189, -0.2947, -0.0355], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2524, -0.2501,  0.0038,  0.4330], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5382, -1.9586,  0.3496,  1.1099], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2050,  0.1505, -0.2406, -0.4005], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.0397,  0.3989, -0.4953,  0.3653], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7627, -0.0205, -0.5599, -0.1850], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.0904,  1.0579, -0.0975,  0.5895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([ 1.5743,  0.9035,  0.9779, -0.8895], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.0109, -0.2602, -0.8932,  0.1411], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.4030, -0.0548, -0.5669, -0.1297], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.6386,  0.0993, -0.3933, -0.3480], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.7746, -1.1094, -0.2718,  0.6255], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.5315, -0.2869,  0.0507,  0.4116], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.2466, -0.1060, -0.7196, -0.0772], grad_fn=<MeanBackward1>),\n",
       " tensor([ 0.2761, -0.4503,  0.1260,  0.8497], grad_fn=<MeanBackward1>),\n",
       " tensor([-0.1959,  0.5530, -0.3217,  0.1470], grad_fn=<MeanBackward1>),\n",
       " tensor([-1.4822,  0.0482, -0.5460, -0.2956], grad_fn=<MeanBackward1>),\n",
       " ...]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "18c674e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = ThemeEmbedder(pd.DataFrame(df_final['book_isbn']),'book_isbn',16)\n",
    "res_tensor = zx()  # or zx.forward()\n",
    "# res_np = res_tensor.detach().cpu().numpy()  # ensure it's a NumPy array\n",
    "\n",
    "# Step 2: Convert to DataFrame\n",
    "embedding_dim = res_np.shape[1]\n",
    "emb_df = pd.DataFrame(res_tensor, columns=[f'book_isbn_emb_{i}' for i in range(16)])\n",
    "\n",
    "# Step 3: Concatenate\n",
    "assert isinstance(df_final, pd.DataFrame), \"df_final must be a DataFrame\"\n",
    "assert df_final.shape[0] == emb_df.shape[0], \"Row count mismatch between df_final and embeddings\"\n",
    "\n",
    "df_final_v1 = pd.concat([df_final.reset_index(drop=True), emb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2184d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>...</th>\n",
       "      <th>book_isbn_emb_6</th>\n",
       "      <th>book_isbn_emb_7</th>\n",
       "      <th>book_isbn_emb_8</th>\n",
       "      <th>book_isbn_emb_9</th>\n",
       "      <th>book_isbn_emb_10</th>\n",
       "      <th>book_isbn_emb_11</th>\n",
       "      <th>book_isbn_emb_12</th>\n",
       "      <th>book_isbn_emb_13</th>\n",
       "      <th>book_isbn_emb_14</th>\n",
       "      <th>book_isbn_emb_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.6242, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.9681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.9258, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.1471, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.9147, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.4615, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.5936, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.2231, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2585, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.5205, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.1980, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.0799, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.0615, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.4259, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.3419, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.3888, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.8050, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0461, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0926, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.9766, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.4712, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7039, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.6822, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3006, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0947, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.8083, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0425, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.8625, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.0250, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.2498, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.3142, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.8525, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3890, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.9732, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.5231, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.7937, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(2.0855, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0427, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.9218, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1840, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.0668, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1685, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1564, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.5935, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3035, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0429, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.5444, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.7810, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3132, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1558, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count                                 reading_skill_name  \\\n",
       "0                 0.42  Making Inferences, Illustrations or other Visu...   \n",
       "1                 0.62  Illustrations or other Visual Elements, Fact a...   \n",
       "2                 0.62  Making Inferences, Illustrations or other Visu...   \n",
       "3                 0.26                                               None   \n",
       "4                 0.10                                               None   \n",
       "\n",
       "                                theme_name  ...  \\\n",
       "0                  Fun Science, Technology  ...   \n",
       "1  History, Technology, Places of Interest  ...   \n",
       "2  Sports & Games, Fitness, Healthy Habits  ...   \n",
       "3    Emotions & Feelings, Family & Friends  ...   \n",
       "4     Funny Stories, Our Friends in Nature  ...   \n",
       "\n",
       "                              book_isbn_emb_6  \\\n",
       "0   tensor(0.6242, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.1980, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.4712, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3142, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.0668, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                              book_isbn_emb_7  \\\n",
       "0  tensor(-0.9681, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.0799, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.7039, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.8525, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.1685, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                              book_isbn_emb_8  \\\n",
       "0  tensor(-1.9258, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.0615, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.6822, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3890, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.1564, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                              book_isbn_emb_9  \\\n",
       "0   tensor(1.1471, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.4259, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.3006, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(1.9732, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.5935, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_10  \\\n",
       "0   tensor(0.9147, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.3419, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.0947, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(1.5231, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3035, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_11  \\\n",
       "0   tensor(1.4615, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.3888, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.8083, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.7937, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.0429, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_12  \\\n",
       "0  tensor(-0.5936, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.8050, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.0425, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(2.0855, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.5444, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_13  \\\n",
       "0   tensor(0.2231, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.0461, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.8625, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.0427, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.7810, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_14  \\\n",
       "0  tensor(-1.2585, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.0926, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-1.0250, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.9218, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3132, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                             book_isbn_emb_15  \n",
       "0  tensor(-1.5205, grad_fn=<UnbindBackward0>)  \n",
       "1  tensor(-0.9766, grad_fn=<UnbindBackward0>)  \n",
       "2  tensor(-0.2498, grad_fn=<UnbindBackward0>)  \n",
       "3   tensor(0.1840, grad_fn=<UnbindBackward0>)  \n",
       "4   tensor(0.1558, grad_fn=<UnbindBackward0>)  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = ThemeEmbedder(pd.DataFrame(df_final['book_isbn']),'book_isbn',16)\n",
    "res_tensor = zx()  # or zx.forward()\n",
    "# res_np = res_tensor.detach().cpu().numpy()  # ensure it's a NumPy array\n",
    "\n",
    "# Step 2: Convert to DataFrame\n",
    "embedding_dim = res_np.shape[1]\n",
    "emb_df = pd.DataFrame(res_tensor, columns=[f'book_isbn_emb_{i}' for i in range(16)])\n",
    "\n",
    "# Step 3: Concatenate\n",
    "assert isinstance(df_final, pd.DataFrame), \"df_final must be a DataFrame\"\n",
    "assert df_final.shape[0] == emb_df.shape[0], \"Row count mismatch between df_final and embeddings\"\n",
    "\n",
    "df_final_v1 = pd.concat([df_final.reset_index(drop=True), emb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2feae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "['book_series', 'reading_skill_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2c6ef1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = ThemeEmbedder(pd.DataFrame(df_final['reading_skill_name']),'reading_skill_name',4)\n",
    "res_tensor = zx()  # or zx.forward()\n",
    "# res_np = res_tensor.detach().cpu().numpy()  # ensure it's a NumPy array\n",
    "\n",
    "# Step 2: Convert to DataFrame\n",
    "embedding_dim = res_np.shape[1]\n",
    "emb_df = pd.DataFrame(res_tensor, columns=[f'read_emb_{i}' for i in range(4)])\n",
    "\n",
    "# Step 3: Concatenate\n",
    "assert isinstance(df_final, pd.DataFrame), \"df_final must be a DataFrame\"\n",
    "assert df_final.shape[0] == emb_df.shape[0], \"Row count mismatch between df_final and embeddings\"\n",
    "\n",
    "df_final_v1 = pd.concat([df_final.reset_index(drop=True), emb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f08542a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>title_plus_author</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_type</th>\n",
       "      <th>long_description</th>\n",
       "      <th>min_grade</th>\n",
       "      <th>max_grade</th>\n",
       "      <th>readable_page_count</th>\n",
       "      <th>reading_skill_name</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_Portuguese</th>\n",
       "      <th>lang_Spanish</th>\n",
       "      <th>grade_emb_0</th>\n",
       "      <th>grade_emb_1</th>\n",
       "      <th>grade_emb_2</th>\n",
       "      <th>grade_emb_3</th>\n",
       "      <th>read_emb_0</th>\n",
       "      <th>read_emb_1</th>\n",
       "      <th>read_emb_2</th>\n",
       "      <th>read_emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781638973744</td>\n",
       "      <td>forces and changes in motion by christina,earley</td>\n",
       "      <td>Physical Science</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Do you wonder about the world around us? In th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Fun Science, Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.6101, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1556, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4481, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0786, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781427121141</td>\n",
       "      <td>forensic investigations of the ancient egyptia...</td>\n",
       "      <td>Forensic Footprints of Ancient Worlds</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Can modern forensic tools help us uncover new ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Illustrations or other Visual Elements, Fact a...</td>\n",
       "      <td>History, Technology, Places of Interest</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.4210, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0188, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.6919, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1112, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780778789222</td>\n",
       "      <td>soccer in action by niki,walker</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Goooaaaallllll! Crabtree scores with Soccer in...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Making Inferences, Illustrations or other Visu...</td>\n",
       "      <td>Sports &amp; Games, Fitness, Healthy Habits</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(0.8714, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.1184, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0281, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.2436, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.7336, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.0518, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.2328, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.1401, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781039625440</td>\n",
       "      <td>scared (pè) bilingual eng/cre by amy,culliford</td>\n",
       "      <td>None</td>\n",
       "      <td>PDF</td>\n",
       "      <td>In this book, young readers will learn to reco...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Emotions &amp; Feelings, Family &amp; Friends</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tensor(-0.3938, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0132, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.1115, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3705, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.6249, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.4469, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781532420764</td>\n",
       "      <td>cody eats / cody come by brenda ponnay</td>\n",
       "      <td>Cody the Dog Bilingual</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Bilingual Spanish / English Language Edition C...</td>\n",
       "      <td>pk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>Funny Stories, Our Friends in Nature</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(-0.3938, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.0132, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3345, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.4681, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(1.1115, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-0.3705, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(0.6249, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "      <td>tensor(-1.4469, grad_fn=&lt;UnbindBackward0&gt;)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_isbn                                  title_plus_author  \\\n",
       "0  9781638973744   forces and changes in motion by christina,earley   \n",
       "1  9781427121141  forensic investigations of the ancient egyptia...   \n",
       "2  9780778789222                    soccer in action by niki,walker   \n",
       "3  9781039625440     scared (pè) bilingual eng/cre by amy,culliford   \n",
       "4  9781532420764             cody eats / cody come by brenda ponnay   \n",
       "\n",
       "                             book_series book_type  \\\n",
       "0                       Physical Science       PDF   \n",
       "1  Forensic Footprints of Ancient Worlds       PDF   \n",
       "2                       Sports in Action       PDF   \n",
       "3                                   None       PDF   \n",
       "4                 Cody the Dog Bilingual       PDF   \n",
       "\n",
       "                                    long_description min_grade max_grade  \\\n",
       "0  Do you wonder about the world around us? In th...         3         5   \n",
       "1  Can modern forensic tools help us uncover new ...         3         5   \n",
       "2  Goooaaaallllll! Crabtree scores with Soccer in...         3         5   \n",
       "3  In this book, young readers will learn to reco...        pk         1   \n",
       "4  Bilingual Spanish / English Language Edition C...        pk         1   \n",
       "\n",
       "   readable_page_count                                 reading_skill_name  \\\n",
       "0                 0.42  Making Inferences, Illustrations or other Visu...   \n",
       "1                 0.62  Illustrations or other Visual Elements, Fact a...   \n",
       "2                 0.62  Making Inferences, Illustrations or other Visu...   \n",
       "3                 0.26                                               None   \n",
       "4                 0.10                                               None   \n",
       "\n",
       "                                theme_name  ... lang_Portuguese  lang_Spanish  \\\n",
       "0                  Fun Science, Technology  ...           False         False   \n",
       "1  History, Technology, Places of Interest  ...           False         False   \n",
       "2  Sports & Games, Fitness, Healthy Habits  ...           False         False   \n",
       "3    Emotions & Feelings, Family & Friends  ...           False         False   \n",
       "4     Funny Stories, Our Friends in Nature  ...           False          True   \n",
       "\n",
       "                                  grade_emb_0  \\\n",
       "0   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.8714, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3938, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3938, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_1  \\\n",
       "0  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.1184, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.0132, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.0132, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_2  \\\n",
       "0   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "2   tensor(0.0281, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3345, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                  grade_emb_3  \\\n",
       "0  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-1.2436, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.4681, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.4681, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                   read_emb_0  \\\n",
       "0  tensor(-0.6101, grad_fn=<UnbindBackward0>)   \n",
       "1  tensor(-0.4210, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.7336, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(1.1115, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(1.1115, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                   read_emb_1  \\\n",
       "0   tensor(0.1556, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.0188, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.0518, grad_fn=<UnbindBackward0>)   \n",
       "3  tensor(-0.3705, grad_fn=<UnbindBackward0>)   \n",
       "4  tensor(-0.3705, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                   read_emb_2  \\\n",
       "0   tensor(0.4481, grad_fn=<UnbindBackward0>)   \n",
       "1   tensor(0.6919, grad_fn=<UnbindBackward0>)   \n",
       "2  tensor(-0.2328, grad_fn=<UnbindBackward0>)   \n",
       "3   tensor(0.6249, grad_fn=<UnbindBackward0>)   \n",
       "4   tensor(0.6249, grad_fn=<UnbindBackward0>)   \n",
       "\n",
       "                                   read_emb_3  \n",
       "0   tensor(0.0786, grad_fn=<UnbindBackward0>)  \n",
       "1   tensor(0.1112, grad_fn=<UnbindBackward0>)  \n",
       "2   tensor(0.1401, grad_fn=<UnbindBackward0>)  \n",
       "3  tensor(-1.4469, grad_fn=<UnbindBackward0>)  \n",
       "4  tensor(-1.4469, grad_fn=<UnbindBackward0>)  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fcaeecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zx = ThemeEmbedder(pd.DataFrame(df_final['book_series']),'book_series',16)\n",
    "res_tensor = zx()  # or zx.forward()\n",
    "# res_np = res_tensor.detach().cpu().numpy()  # ensure it's a NumPy array\n",
    "\n",
    "# Step 2: Convert to DataFrame\n",
    "embedding_dim = res_np.shape[1]\n",
    "emb_df = pd.DataFrame(res_tensor, columns=[f'book_series_emb_{i}' for i in range(16)])\n",
    "\n",
    "# Step 3: Concatenate\n",
    "assert isinstance(df_final, pd.DataFrame), \"df_final must be a DataFrame\"\n",
    "assert df_final.shape[0] == emb_df.shape[0], \"Row count mismatch between df_final and embeddings\"\n",
    "\n",
    "df_final_v1 = pd.concat([df_final.reset_index(drop=True), emb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ba4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.cloud_storage.redshift_connection import redshift_connection\n",
    "\n",
    "connection = redshift_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66744cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 11:29:41,482 - side - DEBUG - Attempting to read SQL file: sql_files/item_query.sql\n",
      "2025-08-18 11:29:41,484 - side - INFO - Successfully read SQL file: sql_files/item_query.sql\n",
      "2025-08-18 11:29:44,013 - read_shift - INFO - Connected to Redshift successfully.\n",
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/cloud_storage/redshift_connection.py:82: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "2025-08-18 11:31:16,483 - read_shift - INFO - Query executed successfully, retrieved 12189 rows.\n",
      "2025-08-18 11:31:16,484 - read_shift - INFO - Connection closed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>book_series</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>rights</th>\n",
       "      <th>illustrators</th>\n",
       "      <th>interactive</th>\n",
       "      <th>search_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>clicks_students</th>\n",
       "      <th>quality_clicks</th>\n",
       "      <th>quality_clicks_students</th>\n",
       "      <th>students_completed_book</th>\n",
       "      <th>students_completed_75_per_book</th>\n",
       "      <th>per_75_completed_unique_books</th>\n",
       "      <th>completion_rate</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>total_pages</th>\n",
       "      <th>read_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>9781427121479</td>\n",
       "      <td>Animals of the World</td>\n",
       "      <td>Toby,Reynolds</td>\n",
       "      <td>Quick-Reference Atlases</td>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlas, Animals, Includes index, Includes bolde...</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>38.61</td>\n",
       "      <td>783991.0</td>\n",
       "      <td>53414.0</td>\n",
       "      <td>23522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>9781427194763</td>\n",
       "      <td>Bloodsucking Lice and Fleas</td>\n",
       "      <td>Ellen,Rodger</td>\n",
       "      <td>Creepy Crawlies</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>176.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>46.71</td>\n",
       "      <td>25660.0</td>\n",
       "      <td>7290.0</td>\n",
       "      <td>4910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>9781427164292</td>\n",
       "      <td>Colonial Home</td>\n",
       "      <td>Bobbie,Kalman</td>\n",
       "      <td>Historic Communities</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>14578.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>9781427197559</td>\n",
       "      <td>Drake</td>\n",
       "      <td>Lynn,Peppas</td>\n",
       "      <td>Superstars!</td>\n",
       "      <td>2011-08-15</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>844.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>42.61</td>\n",
       "      <td>1242214.0</td>\n",
       "      <td>50670.0</td>\n",
       "      <td>24436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243</td>\n",
       "      <td>9781427166807</td>\n",
       "      <td>Golf in Action</td>\n",
       "      <td>Hannelore,Sotzek</td>\n",
       "      <td>Sports in Action</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>World</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.29</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      book_isbn                   book_title           authors  \\\n",
       "0   38  9781427121479         Animals of the World     Toby,Reynolds   \n",
       "1   66  9781427194763  Bloodsucking Lice and Fleas      Ellen,Rodger   \n",
       "2  107  9781427164292                Colonial Home     Bobbie,Kalman   \n",
       "3  125  9781427197559                        Drake       Lynn,Peppas   \n",
       "4  243  9781427166807               Golf in Action  Hannelore,Sotzek   \n",
       "\n",
       "               book_series publication_date rights illustrators interactive  \\\n",
       "0  Quick-Reference Atlases       2018-08-10  World         None       False   \n",
       "1          Creepy Crawlies       2010-07-15  World         None       False   \n",
       "2     Historic Communities       2000-10-31  World         None       False   \n",
       "3              Superstars!       2011-08-15  World         None       False   \n",
       "4         Sports in Action       2000-10-31  World         None       False   \n",
       "\n",
       "                                     search_keywords  ... clicks_students  \\\n",
       "0  Atlas, Animals, Includes index, Includes bolde...  ...          1065.0   \n",
       "1                                               None  ...           176.0   \n",
       "2                                               None  ...            50.0   \n",
       "3                                               None  ...           844.0   \n",
       "4                                               None  ...            24.0   \n",
       "\n",
       "  quality_clicks quality_clicks_students students_completed_book  \\\n",
       "0         1133.0                   875.0                   349.0   \n",
       "1          208.0                   165.0                    78.0   \n",
       "2           51.0                    38.0                    13.0   \n",
       "3         1204.0                   734.0                   320.0   \n",
       "4           19.0                    15.0                     6.0   \n",
       "\n",
       "  students_completed_75_per_book per_75_completed_unique_books  \\\n",
       "0                          773.0                          85.0   \n",
       "1                          159.0                          95.0   \n",
       "2                           34.0                          87.0   \n",
       "3                          697.0                          92.0   \n",
       "4                           14.0                          82.0   \n",
       "\n",
       "  completion_rate time_spent  total_pages read_pages  \n",
       "0           38.61   783991.0      53414.0    23522.0  \n",
       "1           46.71    25660.0       7290.0     4910.0  \n",
       "2           33.33    14578.0       2604.0      733.0  \n",
       "3           42.61  1242214.0      50670.0    24436.0  \n",
       "4           35.29     1113.0        928.0      311.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_query = 'sql_files/item_query.sql'\n",
    "book_df = connection.redshift_query_fetching_as_df(item_query)\n",
    "book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41ded48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tta/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.components.data_transformation import book_data_transformation,user_data_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43043e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/components/data_transformation.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  book_df['long_description'].fillna('unk',inplace=True)\n",
      "Batches:   0%|          | 0/381 [00:00<?, ?it/s]/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|██████████| 381/381 [00:07<00:00, 52.29it/s]\n",
      "Batches:   0%|          | 0/381 [00:00<?, ?it/s]/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|██████████| 381/381 [00:36<00:00, 10.41it/s]\n",
      "Batches:   0%|          | 0/381 [00:00<?, ?it/s]/opt/anaconda3/envs/tta/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|██████████| 381/381 [00:32<00:00, 11.79it/s]\n",
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/components/data_transformation.py:204: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  book_series_df['fiction_nonfiction'].fillna('unk',inplace =True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved and merged into feature_mappings/theme_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/category_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/reading_skill_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/grades_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/book_code_to_idx.json\n"
     ]
    }
   ],
   "source": [
    "item_df,  book_feature_count, emb_count =  book_data_transformation(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "887beefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookDataset(Dataset):\n",
    "    def __init__(self,  book_features_df, book_feature_cols):\n",
    "        \"\"\"\n",
    "        interactions_df: includes user_id, book_code, label, and interaction-level features\n",
    "        book_features_df: indexed by book_code, contains theme_ids, category_ids, and other features\n",
    "        book_feature_cols: list of book feature column names\n",
    "        interaction_feature_cols: list of interaction-level feature column names\n",
    "        \"\"\"\n",
    "        \n",
    "        self.book_features_df = book_features_df\n",
    "        self.book_feature_cols = book_feature_cols\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.book_features_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.book_features_df.iloc[idx]\n",
    "        book_code = row[\"book_code\"]\n",
    "\n",
    "        # --- 1. Get book-level features ---\n",
    "        # book_info = self.book_features_df.loc[book_code]\n",
    "\n",
    "        theme_ids = row[\"theme_ids\"]  # already list[int]\n",
    "        category_ids = row[\"category_ids\"]  # already list[int]\n",
    "        reading_skill_ids = row[\"reading_skill_ids\"]  # already list[int]\n",
    "        grades_ids = row['grades_ids']  # already list[int]\n",
    "        book_code_ids= row['book_code_ids']  # already list[int]\n",
    "\n",
    "\n",
    "        # 'countries_ids','states_ids','zipcode_ids','teacher_ids','school_ids'\n",
    "        \n",
    "\n",
    "        book_features = np.array(row[self.book_feature_cols], dtype=np.float32)\n",
    "\n",
    "        # --- 2. Get interaction-level features ---\n",
    "        # user_features = np.array(row[self.interaction_feature_cols], dtype=np.float32)\n",
    "\n",
    "        # # --- 3. Merge into one \"other_features\" vector ---\n",
    "        # other_features = torch.tensor(\n",
    "        #     np.concatenate([book_features, interaction_features]),\n",
    "        #     dtype=torch.float32\n",
    "        # )\n",
    "\n",
    "        return {\n",
    "            \"book_code\": book_code,\n",
    "            \"theme_ids\": torch.tensor(theme_ids, dtype=torch.long),\n",
    "            \"category_ids\": torch.tensor(category_ids, dtype=torch.long),\n",
    "            \"reading_skill_ids\":torch.tensor(reading_skill_ids, dtype=torch.long),\n",
    "            \"grades_ids\" : torch.tensor(grades_ids , dtype=torch.long) ,\n",
    "            \"book_code_ids\": torch.tensor(book_code_ids , dtype=torch.long),\n",
    "            \"book_features\": torch.tensor(book_features, dtype=torch.float32)\n",
    "           \n",
    "        }\n",
    "\n",
    "\n",
    "def collate_bookonly_fn(batch):\n",
    "    # --------- Helper to pad & mask any list-of-tensors field ----------\n",
    "    def pad_and_mask(key):\n",
    "        seqs = [torch.as_tensor(item[key], dtype=torch.long) for item in batch]\n",
    "        \n",
    "        padded = pad_sequence(seqs, batch_first=True, padding_value=0)  # [B, max_len]\n",
    "        mask = (padded != 0).long()  # [B, max_len] boolean mask\n",
    "        return padded, mask\n",
    "\n",
    "    # Book-level multi-ID fields\n",
    "    theme_ids, theme_mask = pad_and_mask(\"theme_ids\")\n",
    "    category_ids, category_mask = pad_and_mask(\"category_ids\")\n",
    "    reading_skill_ids, reading_skill_mask = pad_and_mask(\"reading_skill_ids\")\n",
    "    grades_ids, grades_mask = pad_and_mask(\"grades_ids\")\n",
    "    book_code_ids, book_code_mask = pad_and_mask(\"book_code_ids\")\n",
    "\n",
    "\n",
    "    # Scalar / dense features\n",
    "    book_features = torch.stack([torch.as_tensor(item[\"book_features\"], dtype=torch.float32) for item in batch])\n",
    "\n",
    "    book_codes = [item[\"book_code\"] for item in batch]\n",
    "    return {\n",
    "        # --- Book-level IDs ---\n",
    "        \"book_code\": book_codes,\n",
    "        \"theme_ids\": theme_ids, \"theme_mask\": theme_mask,\n",
    "        \"category_ids\": category_ids, \"category_mask\": category_mask,\n",
    "        \"reading_skill_ids\": reading_skill_ids, \"reading_skill_mask\": reading_skill_mask,\n",
    "        \"grades_ids\": grades_ids, \"grades_mask\": grades_mask,\n",
    "        \"book_code_ids\": book_code_ids, \"book_code_mask\": book_code_mask,\n",
    "\n",
    "        # --- Dense features & labels ---\n",
    "       \n",
    "        \"book_features\": book_features,\n",
    "       \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15a0bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_author_title =[f\"emb_title_author_{i}\" for i in range(384)]\n",
    "columns_long_description = [f\"emb_desc_{i}\" for i in range(384)]\n",
    "columns_book_series = [f\"emb_book_series_{i}\" for i in range(384)]\n",
    "columns_add = ['readable_page_count','book_type_binary', 'fn_Fiction', 'fn_Non-Fiction', 'fn_unk',\n",
    "       'lang_English', 'lang_French', 'lang_Haitian French Creole',\n",
    "       'lang_Mandarin', 'lang_Portuguese', 'lang_Spanish']\n",
    "\n",
    "columns_learn_emb = ['book_code','book_code_ids','grades_ids','reading_skill_ids', 'category_ids','theme_ids']\n",
    "\n",
    "book_feature_cols = columns_author_title + columns_long_description + columns_book_series + columns_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d8fd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = BookDataset( item_df, book_feature_cols)\n",
    "trainloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_bookonly_fn)\n",
    "\n",
    "# dataset = BookInteractionDataset( val[:5], item_df, book_feature_cols, interaction_feature_cols)\n",
    "# valloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=book_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1597c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_code': ['9781645271222', '9781641289337'], 'theme_ids': tensor([[98,  0],\n",
      "        [29, 21]]), 'theme_mask': tensor([[1, 0],\n",
      "        [1, 1]]), 'category_ids': tensor([[7],\n",
      "        [1]]), 'category_mask': tensor([[1],\n",
      "        [1]]), 'reading_skill_ids': tensor([], size=(2, 0), dtype=torch.int64), 'reading_skill_mask': tensor([], size=(2, 0), dtype=torch.int64), 'grades_ids': tensor([[1, 2, 3, 4],\n",
      "        [9, 8, 0, 0]]), 'grades_mask': tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 0, 0]]), 'book_code_ids': tensor([[ 557],\n",
      "        [8789]]), 'book_code_mask': tensor([[1],\n",
      "        [1]]), 'book_features': tensor([[-0.0324,  0.0229,  0.1106,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0175,  0.0198, -0.0207,  ...,  0.0000,  0.0000,  0.0000]])}\n"
     ]
    }
   ],
   "source": [
    "for i in trainloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab925b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['book_code', 'theme_ids', 'theme_mask', 'category_ids', 'category_mask', 'reading_skill_ids', 'reading_skill_mask', 'grades_ids', 'grades_mask', 'book_code_ids', 'book_code_mask', 'book_features'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca389d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.main_utils import save_dict_to_json,  load_json_file\n",
    "fi = load_json_file('model_parmater.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45bdaaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_feature_count': {'themes_count': 108,\n",
       "  'book_count': 12190,\n",
       "  'grade_count': 11,\n",
       "  'reading_skills_count': 13,\n",
       "  'category_count': 9},\n",
       " 'emb_count': {'themes_count': 8,\n",
       "  'book_count': 16,\n",
       "  'grade_count': 4,\n",
       "  'reading_skills_count': 4,\n",
       "  'category_count': 4},\n",
       " 'user_feature_count': {'themes_count': 108,\n",
       "  'book_count': 12190,\n",
       "  'reading_skills_count': 13,\n",
       "  'category_count': 9,\n",
       "  'country_count': 160,\n",
       "  'state_count': 558,\n",
       "  'zipcode_count': 15985,\n",
       "  'teacher_count': 112147,\n",
       "  'school_count': 84655},\n",
       " 'user_emb_count': {'themes_count': 8,\n",
       "  'book_count': 16,\n",
       "  'reading_skills_count': 4,\n",
       "  'category_count': 4,\n",
       "  'country_count': 8,\n",
       "  'state_count': 10,\n",
       "  'zipcode_count': 14,\n",
       "  'teacher_count': 16,\n",
       "  'school_count': 16},\n",
       " 'book_feature_dim': 1163,\n",
       " 'user_feature_dim': 20}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5819eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.model import TwoTowerModel\n",
    "model = TwoTowerModel(fi['book_feature_count'], fi['user_feature_count'],\n",
    "                 fi['emb_count'], fi['user_emb_count'],\n",
    "                  book_feature_dim=fi['book_feature_dim'], user_feature_dim=fi['user_feature_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87380cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5aefee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TwoTowerModel checkpoint loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Recreate the model with the same architecture\n",
    "# model = TwoTowerModel(\n",
    "#     book_feature_count=...,   # same values used in training\n",
    "#     user_feature_count=...,\n",
    "#     emb_count=...,\n",
    "#     user_emb_count=...,\n",
    "#     book_feature_dim=...,\n",
    "#     user_feature_dim=...\n",
    "# )\n",
    "\n",
    "# Move to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Load checkpoint weights\n",
    "checkpoint_path = \"checkpoints/two_tower_best.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()   # set to inference mode\n",
    "print(\"✅ TwoTowerModel checkpoint loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aebf883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0345, -0.0031, -0.0741,  0.0136,  0.0602,  0.0313, -0.0285,  0.0005,\n",
       "          0.0346,  0.1360, -0.0284, -0.0429,  0.1038,  0.0773, -0.0959,  0.0612,\n",
       "         -0.1399, -0.0237,  0.0811,  0.0789, -0.0233, -0.2071,  0.1142, -0.0883,\n",
       "         -0.0120, -0.0794,  0.0558,  0.0983,  0.0328,  0.1238, -0.0798,  0.0447,\n",
       "          0.1192,  0.0621,  0.0233, -0.0061, -0.0913,  0.0908, -0.0437,  0.1269,\n",
       "         -0.0089, -0.0619,  0.1195, -0.0511, -0.0358,  0.0556,  0.0120,  0.1017,\n",
       "         -0.0559,  0.1378,  0.1520,  0.0994,  0.0370, -0.0460, -0.1077,  0.0527,\n",
       "          0.0162, -0.1324,  0.0456, -0.1308, -0.0436, -0.0608,  0.0868,  0.0588],\n",
       "        [-0.0273,  0.0073, -0.1011,  0.0659,  0.0428,  0.0323, -0.0554, -0.0478,\n",
       "          0.0038,  0.0387, -0.0406, -0.0568, -0.0322,  0.1490, -0.0302,  0.0435,\n",
       "         -0.1402, -0.0376,  0.1389,  0.0846, -0.0247, -0.1431,  0.0434, -0.0463,\n",
       "         -0.0586, -0.0922, -0.0261,  0.0035, -0.0694,  0.1137, -0.1025,  0.1026,\n",
       "          0.1599,  0.2153,  0.0914, -0.0989, -0.0487,  0.0597, -0.0176,  0.1134,\n",
       "          0.0317, -0.0251,  0.0910, -0.0404, -0.0073,  0.0567,  0.0804,  0.0786,\n",
       "         -0.1859,  0.0820,  0.0680,  0.1719,  0.0213, -0.0157, -0.0651,  0.0955,\n",
       "         -0.0121, -0.0681,  0.0455, -0.2008, -0.0502, -0.0161,  0.0490,  0.0660]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_book_vec( i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a5d0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12189, 1169)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding books: 100%|██████████| 96/96 [00:07<00:00, 13.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.utils.main_utils import load_json_file\n",
    "from src.components.model import TwoTowerModel\n",
    "from tqdm import tqdm \n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "def build_and_save_book_embeddings_faiss(model, item_df, book_feature_cols,\n",
    "                                         batch_size=512, device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                         index_path=\"book_index.faiss\",\n",
    "                                         id_map_path=\"book_ids.pkl\"):\n",
    "\n",
    "    fi = load_json_file('model_parmater.json')\n",
    "\n",
    "    dataset = BookDataset( item_df, book_feature_cols)\n",
    "    trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_bookonly_fn)\n",
    "\n",
    "\n",
    "    model = TwoTowerModel(fi['book_feature_count'], fi['user_feature_count'],\n",
    "                    fi['emb_count'], fi['user_emb_count'],\n",
    "                    book_feature_dim=fi['book_feature_dim'], user_feature_dim=fi['user_feature_dim'])\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    all_embeddings = []\n",
    "    book_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "            for batch in tqdm(trainloader, desc=\"Encoding books\"):\n",
    "                batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "                \n",
    "                # Compute embeddings\n",
    "                book_vec = model.get_book_vec(batch)\n",
    "\n",
    "                all_embeddings.append(book_vec.cpu().numpy())\n",
    "                book_ids.extend(batch[\"book_code\"])  # keep mapping book_id → index\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings).astype(\"float32\")  # [N_books, D]\n",
    "\n",
    "    dim = all_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)   # Inner Product (dot product)\n",
    "    index.add(all_embeddings)\n",
    "\n",
    "    # Save index & mapping\n",
    "    faiss.write_index(index, index_path)\n",
    "    with open(id_map_path, \"wb\") as f:\n",
    "        pickle.dump(book_ids, f)\n",
    "\n",
    "    print(f\"✅ Saved FAISS index with {len(book_ids)} books at {index_path}\")\n",
    "    return index, book_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8dfcf157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12189, 64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36748a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# import numpy as np\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import pickle\n",
    "\n",
    "# def build_and_save_book_embeddings_faiss(model, book_df, book_feature_cols,\n",
    "#                                          batch_size=512, device=\"cuda\",\n",
    "#                                          index_path=\"book_index.faiss\",\n",
    "#                                          id_map_path=\"book_ids.pkl\"):\n",
    "#     \"\"\"\n",
    "#     Precompute book embeddings and save them in a FAISS index for fast retrieval.\n",
    "#     \"\"\"\n",
    "#     # Dataset + DataLoader\n",
    "#     book_dataset = BookDataset(book_df, book_feature_cols)\n",
    "#     book_loader = DataLoader(book_dataset,\n",
    "#                              batch_size=batch_size,\n",
    "#                              shuffle=False,\n",
    "#                              collate_fn=collate_bookonly_fn)\n",
    "\n",
    "#     model.eval()\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     book_ids = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(book_loader, desc=\"Encoding books\"):\n",
    "#             batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "            \n",
    "#             # Compute embeddings\n",
    "#             book_vec = model.book_tower(\n",
    "#                 batch[\"theme_ids\"], batch[\"theme_mask\"],\n",
    "#                 batch[\"category_ids\"], batch[\"category_mask\"],\n",
    "#                 batch[\"reading_skill_ids\"], batch[\"reading_skill_mask\"],\n",
    "#                 batch[\"grades_ids\"], batch[\"grades_mask\"],\n",
    "#                 batch[\"book_code_ids\"], batch[\"book_code_mask\"],\n",
    "#                 batch[\"book_features\"]\n",
    "#             )   # [B, D]\n",
    "\n",
    "#             all_embeddings.append(book_vec.cpu().numpy())\n",
    "#             book_ids.extend(batch[\"book_code\"])  # keep mapping book_id → index\n",
    "\n",
    "#     all_embeddings = np.vstack(all_embeddings).astype(\"float32\")  # [N_books, D]\n",
    "\n",
    "#     # --- FAISS Index ---\n",
    "#     dim = all_embeddings.shape[1]\n",
    "#     index = faiss.IndexFlatIP(dim)   # Inner Product (dot product)\n",
    "#     index.add(all_embeddings)\n",
    "\n",
    "#     # Save index & mapping\n",
    "#     faiss.write_index(index, index_path)\n",
    "#     with open(id_map_path, \"wb\") as f:\n",
    "#         pickle.dump(book_ids, f)\n",
    "\n",
    "#     print(f\"✅ Saved FAISS index with {len(book_ids)} books at {index_path}\")\n",
    "#     return index, book_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "397b42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 17:46:22,146 - side - DEBUG - Attempting to read SQL file: sql_files/user_book_platform.sql\n",
      "2025-08-18 17:46:22,152 - side - INFO - Successfully read SQL file: sql_files/user_book_platform.sql\n",
      "2025-08-18 17:46:24,706 - read_shift - INFO - Connected to Redshift successfully.\n",
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/cloud_storage/redshift_connection.py:82: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "2025-08-18 17:58:27,200 - read_shift - INFO - Query executed successfully, retrieved 4973201 rows.\n",
      "2025-08-18 17:58:27,204 - read_shift - INFO - Connection closed.\n",
      "2025-08-18 17:58:27,205 - side - DEBUG - Attempting to read SQL file: sql_files/user_location.sql\n",
      "2025-08-18 17:58:27,207 - side - INFO - Successfully read SQL file: sql_files/user_location.sql\n",
      "2025-08-18 17:58:30,104 - read_shift - INFO - Connected to Redshift successfully.\n",
      "2025-08-18 18:00:04,246 - read_shift - INFO - Query executed successfully, retrieved 658152 rows.\n",
      "2025-08-18 18:00:04,248 - read_shift - INFO - Connection closed.\n",
      "2025-08-18 18:00:04,249 - side - DEBUG - Attempting to read SQL file: sql_files/user_query.sql\n",
      "2025-08-18 18:00:04,250 - side - INFO - Successfully read SQL file: sql_files/user_query.sql\n",
      "2025-08-18 18:00:07,077 - read_shift - INFO - Connected to Redshift successfully.\n",
      "2025-08-18 18:03:36,382 - read_shift - INFO - Query executed successfully, retrieved 4973201 rows.\n",
      "2025-08-18 18:03:36,386 - read_shift - INFO - Connection closed.\n"
     ]
    }
   ],
   "source": [
    "platfrom_query = 'sql_files/user_book_platform.sql'\n",
    "user_platform = connection.redshift_query_fetching_as_df(platfrom_query)\n",
    "location_query = 'sql_files/user_location.sql'\n",
    "user_loc = connection.redshift_query_fetching_as_df(location_query)\n",
    "user_query = 'sql_files/user_query.sql'\n",
    "user_df = connection.redshift_query_fetching_as_df(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47266d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_feature_cols = ['cumulative_web_during_school_hour',\n",
    " 'cumulative_web_after_school_hour',\n",
    " 'cumulative_apple_during_school_hour',\n",
    " 'cumulative_apple_after_school_hour',\n",
    " 'cumulative_android_during_school_hour',\n",
    " 'cumulative_android_after_school_hour',\n",
    " 'cumulative_unk_during_school_hour',\n",
    " 'cumulative_unk_after_school_hour',\n",
    " 'grade_grade 1',\n",
    " 'grade_grade 2',\n",
    " 'grade_grade 3',\n",
    " 'grade_grade 4',\n",
    " 'grade_grade 5',\n",
    " 'grade_kindergarten',\n",
    " 'class_activation_bucket_AC',\n",
    " 'class_activation_bucket_AC0',\n",
    " 'class_activation_bucket_AC1',\n",
    " 'class_activation_bucket_AC2',\n",
    " 'class_activation_bucket_AC3',\n",
    " 'class_activation_bucket_unk',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1a0e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, interactions_df, interaction_feature_cols):\n",
    "        \"\"\"\n",
    "        interactions_df: includes user_id, book_code, label, and interaction-level features\n",
    "        book_features_df: indexed by book_code, contains theme_ids, category_ids, and other features\n",
    "        book_feature_cols: list of book feature column names\n",
    "        interaction_feature_cols: list of interaction-level feature column names\n",
    "        \"\"\"\n",
    "        self.interactions_df = interactions_df.reset_index(drop=True)\n",
    "        # self.book_features_df = book_features_df.set_index(\"book_code\")\n",
    "        # self.book_feature_cols = book_feature_cols\n",
    "        self.interaction_feature_cols = interaction_feature_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.interactions_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.interactions_df.iloc[idx]\n",
    "        # book_code = row[\"book_code\"]\n",
    "\n",
    "        # --- 1. Get book-level features ---\n",
    "        # book_info = self.book_features_df.loc[book_code]\n",
    "\n",
    "        # theme_ids = book_info[\"theme_ids\"]  # already list[int]\n",
    "        # category_ids = book_info[\"category_ids\"]  # already list[int]\n",
    "        # reading_skill_ids = book_info[\"reading_skill_ids\"]  # already list[int]\n",
    "        # grades_ids = book_info['grades_ids']  # already list[int]\n",
    "        # book_code_ids= book_info['book_code_ids']  # already list[int]\n",
    "\n",
    "        last_book_ids = row['book_code_ids']\n",
    "        last_theme_ids = row['theme_ids']\n",
    "        last_category_ids = row['category_ids']\n",
    "        last_reading_skills_id = row['reading_skill_ids']\n",
    "\n",
    "        countries_ids = row['countries_ids']\n",
    "        states_ids = row['states_ids']\n",
    "        zipcode_ids = row['zipcode_ids']\n",
    "        teacher_code_ids = row['teacher_code_ids']\n",
    "        school_code_ids = row['school_code_ids']\n",
    "\n",
    "        # 'countries_ids','states_ids','zipcode_ids','teacher_ids','school_ids'\n",
    "        \n",
    "\n",
    "        # book_features = np.array(book_info[self.book_feature_cols], dtype=np.float32)\n",
    "\n",
    "        # --- 2. Get interaction-level features ---\n",
    "        user_features = np.array(row[self.interaction_feature_cols], dtype=np.float32)\n",
    "\n",
    "        # # --- 3. Merge into one \"other_features\" vector ---\n",
    "        # other_features = torch.tensor(\n",
    "        #     np.concatenate([book_features, interaction_features]),\n",
    "        #     dtype=torch.float32\n",
    "        # )\n",
    "\n",
    "        return {\n",
    "            # \"book_code\": book_code,\n",
    "            # \"theme_ids\": torch.tensor(theme_ids, dtype=torch.long),\n",
    "            # \"category_ids\": torch.tensor(category_ids, dtype=torch.long),\n",
    "            # \"reading_skill_ids\":torch.tensor(reading_skill_ids, dtype=torch.long),\n",
    "            # \"grades_ids\" : torch.tensor(grades_ids , dtype=torch.long) ,\n",
    "            # \"book_code_ids\": torch.tensor(book_code_ids , dtype=torch.long),\n",
    "\n",
    "            \"last_book_ids\" : torch.tensor(last_book_ids , dtype=torch.long),\n",
    "            \"last_theme_ids\" : torch.tensor(last_theme_ids , dtype=torch.long),\n",
    "            \"last_category_ids\" : torch.tensor(last_category_ids , dtype=torch.long),\n",
    "            \"last_reading_skills_id\" : torch.tensor(last_reading_skills_id , dtype=torch.long),\n",
    "\n",
    "            \"countries_ids\" : torch.tensor(countries_ids , dtype=torch.long),\n",
    "            \"states_ids\" : torch.tensor(states_ids, dtype=torch.long),\n",
    "            \"zipcode_ids\" : torch.tensor(zipcode_ids , dtype=torch.long),\n",
    "            \"teacher_code_ids\" : torch.tensor(teacher_code_ids , dtype=torch.long),\n",
    "            \"school_code_ids\" : torch.tensor(school_code_ids , dtype=torch.long),\n",
    "\n",
    "            # \"book_features\": torch.tensor(book_features, dtype=torch.float32),\n",
    "            \"user_features\": torch.tensor(user_features, dtype=torch.float32),\n",
    "            # \"label\": torch.tensor(row[\"label\"], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_useronly_fn(batch):\n",
    "    # --------- Helper to pad & mask any list-of-tensors field ----------\n",
    "    def pad_and_mask(key):\n",
    "        seqs = [torch.as_tensor(item[key], dtype=torch.long) for item in batch]\n",
    "        \n",
    "        padded = pad_sequence(seqs, batch_first=True, padding_value=0)  # [B, max_len]\n",
    "        mask = (padded != 0).long()  # [B, max_len] boolean mask\n",
    "        return padded, mask\n",
    "\n",
    "    # Book-level multi-ID fields\n",
    "    # theme_ids, theme_mask = pad_and_mask(\"theme_ids\")\n",
    "    # category_ids, category_mask = pad_and_mask(\"category_ids\")\n",
    "    # reading_skill_ids, reading_skill_mask = pad_and_mask(\"reading_skill_ids\")\n",
    "    # grades_ids, grades_mask = pad_and_mask(\"grades_ids\")\n",
    "    # book_code_ids, book_code_mask = pad_and_mask(\"book_code_ids\")\n",
    "\n",
    "    # Interaction-level multi-ID fields\n",
    "    last_book_ids, last_book_mask = pad_and_mask(\"last_book_ids\")\n",
    "    last_theme_ids, last_theme_mask = pad_and_mask(\"last_theme_ids\")\n",
    "    last_category_ids, last_category_mask = pad_and_mask(\"last_category_ids\")\n",
    "    last_reading_skills_id, last_reading_skills_mask = pad_and_mask(\"last_reading_skills_id\")\n",
    "\n",
    "    \n",
    "\n",
    "    countries_ids, countries_mask = pad_and_mask(\"countries_ids\")\n",
    "    states_ids, states_mask = pad_and_mask(\"states_ids\")\n",
    "    zipcode_ids, zipcode_mask = pad_and_mask( \"zipcode_ids\")\n",
    "    teacher_ids, teacher_mask = pad_and_mask(\"teacher_code_ids\")\n",
    "    school_ids, school_mask = pad_and_mask(\"school_code_ids\")\n",
    "\n",
    "    # Scalar / dense features\n",
    "    # book_features = torch.stack([torch.as_tensor(item[\"book_features\"], dtype=torch.float32) for item in batch])\n",
    "    user_features = torch.stack([torch.as_tensor(item[\"user_features\"], dtype=torch.float32) for item in batch])\n",
    "    # labels = torch.stack([torch.as_tensor(item[\"label\"], dtype=torch.float32) for item in batch])\n",
    "\n",
    "    return {\n",
    "        # --- Book-level IDs ---\n",
    "        # \"theme_ids\": theme_ids, \"theme_mask\": theme_mask,\n",
    "        # \"category_ids\": category_ids, \"category_mask\": category_mask,\n",
    "        # \"reading_skill_ids\": reading_skill_ids, \"reading_skill_mask\": reading_skill_mask,\n",
    "        # \"grades_ids\": grades_ids, \"grades_mask\": grades_mask,\n",
    "        # \"book_code_ids\": book_code_ids, \"book_code_mask\": book_code_mask,\n",
    "\n",
    "        # --- Interaction-level IDs ---\n",
    "        \"last_book_ids\": last_book_ids, \"last_book_mask\": last_book_mask,\n",
    "        \"last_theme_ids\": last_theme_ids, \"last_theme_mask\": last_theme_mask,\n",
    "        \"last_category_ids\": last_category_ids, \"last_category_mask\": last_category_mask,\n",
    "        \"last_reading_skills_id\": last_reading_skills_id, \"last_reading_skills_mask\": last_reading_skills_mask,\n",
    "\n",
    "        \"countries_ids\": countries_ids, \"countries_mask\": countries_mask,\n",
    "        \"states_ids\": states_ids, \"states_mask\": states_mask,\n",
    "        \"zipcode_ids\": zipcode_ids, \"zipcode_mask\": zipcode_mask,\n",
    "        \"teacher_ids\": teacher_ids, \"teacher_mask\": teacher_mask,\n",
    "        \"school_ids\": school_ids, \"school_mask\": school_mask,\n",
    "\n",
    "        # --- Dense features & labels ---\n",
    "       \n",
    "        # \"book_features\": book_features,\n",
    "        \"user_features\": user_features,\n",
    "        # \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46c210bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_transformation import book_data_transformation,user_data_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c1da118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhaveshraj/recommendation_system/Two-Tower/src/components/data_transformation.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_platform_final['book_code'] = user_platform_final['book_code'].astype('str')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved and merged into feature_mappings/country_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/state_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/zipcode_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/teacher_to_idx.json\n",
      "Dictionary saved and merged into feature_mappings/school_to_idx.json\n"
     ]
    }
   ],
   "source": [
    "child_df,user_feature_count, user_emb_count= user_data_transformation(user_df,user_loc,user_platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b95beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = UserDataset( child_df[:1000], interaction_feature_cols)\n",
    "userloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_useronly_fn)\n",
    "\n",
    "# dataset = BookInteractionDataset( val[:5], item_df, book_feature_cols, interaction_feature_cols)\n",
    "# valloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=book_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c3bb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in userloader:\n",
    "    book_vec = model.get_user_vec(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40a77172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cf9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
